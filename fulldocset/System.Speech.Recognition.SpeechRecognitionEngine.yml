### YamlMime:ManagedReference
items:
- uid: System.Speech.Recognition.SpeechRecognitionEngine
  id: SpeechRecognitionEngine
  children:
  - System.Speech.Recognition.SpeechRecognitionEngine.#ctor
  - System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)
  - System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)
  - System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioState
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged
  - System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout
  - System.Speech.Recognition.SpeechRecognitionEngine.Dispose
  - System.Speech.Recognition.SpeechRecognitionEngine.Dispose(System.Boolean)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted
  - System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout
  - System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  - System.Speech.Recognition.SpeechRecognitionEngine.Grammars
  - System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout
  - System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers
  - System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)
  - System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  - System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted
  - System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates
  - System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)
  - System.Speech.Recognition.SpeechRecognitionEngine.Recognize
  - System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached
  - System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate
  - System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)
  - System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  - System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)
  - System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice
  - System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull
  - System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)
  - System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)
  - System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected
  - System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized
  - System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected
  - System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized
  - System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars
  - System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)
  - System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)
  - System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)
  langs:
  - csharp
  name: SpeechRecognitionEngine
  nameWithType: SpeechRecognitionEngine
  fullName: System.Speech.Recognition.SpeechRecognitionEngine
  type: Class
  summary: "Fornece os meios para acessar e gerenciar um mecanismo de reconhecimento de fala no processo."
  remarks: "Você pode criar uma instância dessa classe para qualquer um dos identificadores de fala instalados. Para obter informações sobre quais identificadores são instalados, use estático <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>       Essa classe é para execução fala reconhecimento mecanismos em processo e fornece controle sobre diversos aspectos de reconhecimento de fala, da seguinte maneira: - para criar um reconhecedor de fala em processo, use um do <xref:System.Speech.Recognition.SpeechRecognitionEngine.%23ctor%2A>construtores.</xref:System.Speech.Recognition.SpeechRecognitionEngine.%23ctor%2A>      -Para gerenciar as gramáticas de reconhecimento de fala, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A>, e <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A>métodos e o <xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A>propriedade.</xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>      -Para configurar a entrada para o reconhecedor, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>, ou <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>      -Para realizar o reconhecimento de fala, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>ou <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>      -Para modificar como reconhecimento trata silêncio ou inesperado de entrada, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>, e <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>Propriedades.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>      -Para alterar o número de alternativas que retorna o reconhecedor, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A>propriedade.</xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A> O reconhecedor retorna resultados de reconhecimento em um <xref:System.Speech.Recognition.RecognitionResult>objeto.</xref:System.Speech.Recognition.RecognitionResult>      -Para sincronizar as alterações para o reconhecedor, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> O reconhecedor usa mais de um thread para executar tarefas.      -Para emular o reconhecedor de entrada, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>e <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>métodos.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>       O objeto SpeechRecognitionEngine é para utilização exclusiva do processo que criar uma instância do objeto. Por outro lado, o que <xref:System.Speech.Recognition.SpeechRecognizer>compartilha um identificador único com qualquer aplicativo que deseja usá-lo.</xref:System.Speech.Recognition.SpeechRecognizer>      > [!NOTE] > Sempre chamada <xref:System.Speech.Recognition.SpeechRecognitionEngine.Dispose%2A>antes de liberar sua última referência para o reconhecedor de fala.</xref:System.Speech.Recognition.SpeechRecognitionEngine.Dispose%2A> Caso contrário, os recursos que está usando não serão liberados até que o coletor de lixo chama o objeto de reconhecedor `Finalize` método."
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. Because this example uses the `Multiple` mode of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> method, it performs recognition until you close the console window or stop debugging.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (  \n      SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: 'public class SpeechRecognitionEngine : IDisposable'
  inheritance:
  - System.Object
  implements:
  - System.IDisposable
  inheritedMembers: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor
  id: '#ctor'
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognitionEngine()
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine()
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Inicializa uma nova instância do <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> classe usando o reconhecedor de fala padrão para o sistema."
  remarks: "Antes de iniciar o reconhecimento de fala o reconhecedor de fala, você deve carregar pelo menos uma gramática de reconhecimento e configurar a entrada do reconhecedor.       Para carregar uma gramática, chame o <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>ou <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>       Para configurar a entrada de áudio, use um dos métodos a seguir:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>"
  syntax:
    content: public SpeechRecognitionEngine ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.#ctor*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)
  id: '#ctor(System.Globalization.CultureInfo)'
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognitionEngine(CultureInfo)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(CultureInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(CultureInfo)
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Inicializa uma nova instância do <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> classe usando o reconhecedor de fala padrão para uma localidade específica."
  remarks: "Microsoft Windows e a API Speech aceitar todos os códigos de país de idioma válidos. Para executar o reconhecimento de fala usando o idioma especificado no `CultureInfo` argumento, um mecanismo de reconhecimento de fala que dá suporte a que o código do país de idioma deve ser instalado. Os mecanismos de reconhecimento de fala fornecido com o Microsoft Windows 7 trabalhar com os seguintes códigos de país de idioma.      -en-GB. Inglês (Reino Unido) - en-US. Inglês (Estados Unidos) - de-DE. Alemão (Alemanha) - es-ES. Espanhol (Espanha) - fr-FR. Francês (França) - ja-JP. Japonês (Japão) - zh-CN. Chinês (China) - zh-TW. Códigos de idioma chinês (Taiwan) de duas letras, como &quot;en&quot;, &quot;fr&quot; ou &quot;es&quot; também são permitidos.       Antes de iniciar o reconhecimento do reconhecedor de fala, você deve carregar a gramática de reconhecimento de fala de pelo menos um e configurar a entrada do reconhecedor.       Para carregar uma gramática, chame o <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>ou <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>       Para configurar a entrada de áudio, use um dos métodos a seguir:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition, and initializes a speech recognizer for the en-US locale.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (  \n      SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public SpeechRecognitionEngine (System.Globalization.CultureInfo culture);
    parameters:
    - id: culture
      type: System.Globalization.CultureInfo
      description: "A localidade que o reconhecedor de fala deve dar suporte."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.#ctor*
  exceptions:
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "Nenhum dos reconhecedores de fala instalados suporte para a localidade especificada, ou <code> culture </code> é a cultura invariável."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>Culture</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)
  id: '#ctor(System.Speech.Recognition.RecognizerInfo)'
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognitionEngine(RecognizerInfo)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(RecognizerInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(RecognizerInfo)
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Inicializa uma nova instância do <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> usando as informações em um <xref href=&quot;System.Speech.Recognition.RecognizerInfo&quot;> </xref> objeto para especificar o reconhecedor para usar."
  remarks: "Você pode criar uma instância dessa classe para qualquer um dos identificadores de fala instalados. Para obter informações sobre quais identificadores são instalados, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>       Antes de iniciar o reconhecimento do reconhecedor de fala, você deve carregar a gramática de reconhecimento de fala de pelo menos um e configurar a entrada do reconhecedor.       Para carregar uma gramática, chame o <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>ou <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>       Para configurar a entrada de áudio, use um dos métodos a seguir:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition, and initializes a speech recognizer that supports the English language.  \n  \n```c#  \n using System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Select a speech recognizer that supports English.  \n      RecognizerInfo info = null;  \n      foreach (RecognizerInfo ri in SpeechRecognitionEngine.InstalledRecognizers())  \n      {  \n        if (ri.Culture.TwoLetterISOLanguageName.Equals(\"en\"))  \n        {  \n          info = ri;  \n          break;  \n        }  \n      }  \n      if (info == null) return;  \n  \n      // Create the selected recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(info))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public SpeechRecognitionEngine (System.Speech.Recognition.RecognizerInfo recognizerInfo);
    parameters:
    - id: recognizerInfo
      type: System.Speech.Recognition.RecognizerInfo
      description: "As informações para o reconhecedor de fala específico."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.#ctor*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)
  id: '#ctor(System.String)'
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognitionEngine(String)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(String)
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Inicializa uma nova instância do <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> classe com um parâmetro de cadeia de caracteres que especifica o nome do identificador a ser usado."
  remarks: "O nome do token do reconhecedor de é o valor do <xref:System.Speech.Recognition.RecognizerInfo.Id%2A>propriedade o <xref:System.Speech.Recognition.RecognizerInfo>objeto retornado pelo <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A>propriedade do reconhecedor de.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A> </xref:System.Speech.Recognition.RecognizerInfo> </xref:System.Speech.Recognition.RecognizerInfo.Id%2A> Para obter uma coleção de todos os identificadores instalados, use estático <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>       Antes de iniciar o reconhecimento do reconhecedor de fala, você deve carregar a gramática de reconhecimento de fala de pelo menos um e configurar a entrada do reconhecedor.       Para carregar uma gramática, chame o <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>ou <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>       Para configurar a entrada de áudio, use um dos métodos a seguir:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition, and creates an instance of the Speech Recognizer 8.0 for Windows (English - US).  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Create an instance of the Microsoft Speech Recognizer 8.0 for  \n      // Windows (English - US).  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(\"MS-1033-80-DESK\"))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized += new EventHandler(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public SpeechRecognitionEngine (string recognizerId);
    parameters:
    - id: recognizerId
      type: System.String
      description: "O nome do token do reconhecedor de fala a ser usado."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.#ctor*
  exceptions:
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "Nenhum reconhecedor de fala com esse nome de token é instalado, ou <code> recognizerId </code> é a cadeia de caracteres vazia (&quot;&quot;)."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>recognizerId</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat
  id: AudioFormat
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioFormat
  nameWithType: SpeechRecognitionEngine.AudioFormat
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Obtém o formato de áudio sendo recebido pelo <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>."
  remarks: "Para configurar a entrada de áudio, use um dos métodos a seguir:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>"
  example:
  - "The example below uses AudioFormat to obtain and display audio format data.  \n  \n```  \nstatic void DisplayAudioDeviceFormat(Label label, SpeechRecognitionEngine recognitionEngine)   \n{  \n  \n  if (recognitionEngine != null && label != null)   \n  {  \n    label.Text = String.Format(\"Encoding Format:         {0}\\n\" +  \n          \"AverageBytesPerSecond    {1}\\n\" +  \n          \"BitsPerSample            {2}\\n\" +  \n          \"BlockAlign               {3}\\n\" +  \n          \"ChannelCount             {4}\\n\" +  \n          \"SamplesPerSecond         {5}\",  \n          recognitionEngine.AudioFormat.EncodingFormat.ToString(),  \n          recognitionEngine.AudioFormat.AverageBytesPerSecond,  \n          recognitionEngine.AudioFormat.BitsPerSample,  \n          recognitionEngine.AudioFormat.BlockAlign,  \n          recognitionEngine.AudioFormat.ChannelCount,  \n          recognitionEngine.AudioFormat.SamplesPerSecond);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat { get; }
    return:
      type: System.Speech.AudioFormat.SpeechAudioFormatInfo
      description: "O formato de áudio na entrada para o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> instância, ou <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> se a entrada não está configurada ou definida como a entrada null."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel
  id: AudioLevel
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioLevel
  nameWithType: SpeechRecognitionEngine.AudioLevel
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Obtém o nível de áudio sendo recebido pelo <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>."
  remarks: "O valor 0 representa silêncio e 100 representa o volume máximo de entrada."
  syntax:
    content: public int AudioLevel { get; }
    return:
      type: System.Int32
      description: "O nível de áudio de entrada para o reconhecedor de fala, de 0 a 100."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated
  id: AudioLevelUpdated
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioLevelUpdated
  nameWithType: SpeechRecognitionEngine.AudioLevelUpdated
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Gerado quando o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> relata o nível de sua entrada de áudio."
  remarks: "O <xref:System.Speech.Recognition.SpeechRecognitionEngine>gera esse evento várias vezes por segundo.</xref:System.Speech.Recognition.SpeechRecognitionEngine> A frequência com que o evento é gerado depende do computador no qual o aplicativo está sendo executado.       Para obter o nível de áudio no momento do evento, use a <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A>propriedade de <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>.</xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs> associado</xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A> Para obter o nível atual de áudio de entrada para o reconhecedor, use o reconhecedor <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A>propriedade.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A>       Quando você cria um delegado AudioLevelUpdated, identifica o método que manipulará o evento. Para associar o evento com o manipulador de eventos, adicione uma instância do representante ao evento. O manipulador de eventos é chamado sempre que o evento ocorre, a menos que você remova o delegado. Para obter mais informações sobre delegados de manipulador de eventos, consulte [eventos e delegados](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example adds a handler for the AudioLevelUpdated event to a <xref:System.Speech.Recognition.SpeechRecognitionEngine> object. The handler outputs the new audio level to the console.  \n  \n```  \nprivate SpeechRecognitionEngine recognizer;  \n  \n// Initialize the SpeechRecognitionEngine object.   \nprivate void Initialize()  \n{  \n  recognizer = new SpeechRecognitionEngine();  \n  \n  // Add an event handler for the AudioLevelUpdated event.  \n  recognizer.AudioLevelUpdated +=   \n   new EventHandler<AudioLevelUpdatedEventArgs>(recognizer_AudioLevelUpdated);  \n  \n  // Add other initialization code here.  \n  \n}  \n  \n// Write the audio level to the console when the AudioLevelUpdated event is raised.  \nvoid recognizer_AudioLevelUpdated(object sender, AudioLevelUpdatedEventArgs e)  \n{  \n  Console.WriteLine(\"The audio level is now: {0}.\", e.AudioLevel);  \n}  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs> AudioLevelUpdated;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioLevelUpdatedEventArgs}
      description: "A ser adicionado."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition
  id: AudioPosition
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioPosition
  nameWithType: SpeechRecognitionEngine.AudioPosition
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Obtém o local atual no fluxo de áudio que está sendo gerado pelo dispositivo que está fornecendo a entrada para o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>."
  remarks: "A propriedade AudioPosition faz referência a posição do dispositivo de entrada no seu fluxo de áudio gerado. Por outro lado, o <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>propriedade faz referência a posição do reconhecedor dentro de sua entrada de áudio.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> Essas posições podem ser diferentes. Por exemplo, se tiver recebido o reconhecedor de entrada para o qual não tem ainda gerado um resultado de reconhecimento e o valor da <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>propriedade é menor que o valor da propriedade AudioPosition.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>"
  example:
  - "In the following example, the in-process speech recognizer uses a dictation grammar to match speech input. A handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> event writes to the console the AudioPosition, <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>, and  <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A> when the speech recognizer detects speech at its input.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognitionEngine recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognition engine for US English.  \n      using (recognizer = new SpeechRecognitionEngine(  \n        new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Create a grammar for finding services in different cities.  \n        Choices services = new Choices(new string[] { \"restaurants\", \"hotels\", \"gas stations\" });  \n        Choices cities = new Choices(new string[] { \"Seattle\", \"Boston\", \"Dallas\" });  \n  \n        GrammarBuilder findServices = new GrammarBuilder(\"Find\");  \n        findServices.Append(services);  \n        findServices.Append(\"near\");  \n        findServices.Append(cities);  \n  \n        // Create a Grammar object from the GrammarBuilder and load it to the recognizer.  \n        Grammar servicesGrammar = new Grammar(findServices);  \n        recognizer.LoadGrammarAsync(servicesGrammar);  \n  \n        // Add handlers for events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  \n  \n        // Start asynchronous recognition.  \n        recognizer.RecognizeAsync();  \n        Console.WriteLine(\"Starting asynchronous recognition...\");  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Gather information about detected speech and write it to the console.  \n    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine();  \n      Console.WriteLine(\"Speech detected:\");  \n      Console.WriteLine(\"  Audio level: \" + recognizer.AudioLevel);  \n      Console.WriteLine(\"  Audio position at the event: \" + e.AudioPosition);  \n      Console.WriteLine(\"  Current audio position: \" + recognizer.AudioPosition);  \n      Console.WriteLine(\"  Current recognizer audio position: \" +   \n        recognizer.RecognizerAudioPosition);  \n    }  \n  \n    // Write the text of the recognition result to the console.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"\\nSpeech recognized: \" + e.Result.Text);  \n  \n      // Add event handler code here.  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public TimeSpan AudioPosition { get; }
    return:
      type: System.TimeSpan
      description: "O local atual no fluxo de áudio que está sendo gerado pelo dispositivo de entrada."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred
  id: AudioSignalProblemOccurred
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioSignalProblemOccurred
  nameWithType: SpeechRecognitionEngine.AudioSignalProblemOccurred
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Gerado quando o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> detecta um problema no sinal de áudio."
  remarks: "Para obter o problema, use a <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A>propriedade de <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>.</xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs> associado</xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A>       Quando você cria um delegado AudioSignalProblemOccurred, identifica o método que manipulará o evento. Para associar o evento com o manipulador de eventos, adicione uma instância do representante ao evento. O manipulador de eventos é chamado sempre que o evento ocorre, a menos que você remova o delegado. Para obter mais informações sobre delegados de manipulador de eventos, consulte [eventos e delegados](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example defines an event handler that gathers information about an AudioSignalProblemOccurred event.  \n  \n```  \nprivate SpeechRecognitionEngine recognizer;  \n  \n// Initialize the speech recognition engine.  \nprivate void Initialize()  \n{  \n  recognizer = new SpeechRecognitionEngine();  \n  \n  // Add a handler for the AudioSignalProblemOccurred event.  \n  recognizer.AudioSignalProblemOccurred +=   \n    new EventHandler<AudioSignalProblemOccurredEventArgs>(  \n      recognizer_AudioSignalProblemOccurred);  \n}  \n  \n// Gather information when the AudioSignalProblemOccurred event is raised.  \nvoid recognizer_AudioSignalProblemOccurred(object sender, AudioSignalProblemOccurredEventArgs e)  \n{  \n  StringBuilder details = new StringBuilder();  \n  \n  details.AppendLine(\"Audio signal problem information:\");  \n  details.AppendFormat(  \n    \" Audio level:               {0}\" + Environment.NewLine +  \n    \" Audio position:            {1}\" + Environment.NewLine +  \n    \" Audio signal problem:      {2}\" + Environment.NewLine +  \n    \" Recognition engine audio position: {3}\" + Environment.NewLine,  \n    e.AudioLevel, e.AudioPosition,  e.AudioSignalProblem,  \n    e.recoEngineAudioPosition);  \n  \n  // Insert additional event handler code here.  \n}  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs> AudioSignalProblemOccurred;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioSignalProblemOccurredEventArgs}
      description: "A ser adicionado."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioState
  id: AudioState
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioState
  nameWithType: SpeechRecognitionEngine.AudioState
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioState
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Obtém o estado do áudio sendo recebido pelo <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>."
  remarks: "A propriedade AudioState representa o estado de áudio com um membro do <xref:System.Speech.Recognition.AudioState>enumeração.</xref:System.Speech.Recognition.AudioState>"
  syntax:
    content: public System.Speech.Recognition.AudioState AudioState { get; }
    return:
      type: System.Speech.Recognition.AudioState
      description: "O estado da entrada de áudio para o reconhecedor de fala."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.AudioState*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged
  id: AudioStateChanged
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioStateChanged
  nameWithType: SpeechRecognitionEngine.AudioStateChanged
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Gerado quando as alterações de estado no áudio sendo recebidos pelo <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>."
  remarks: "Para obter o estado de áudio no momento do evento, use a <xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A>propriedade de <xref:System.Speech.Recognition.AudioStateChangedEventArgs>.</xref:System.Speech.Recognition.AudioStateChangedEventArgs> associado</xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A> Para obter o estado atual de áudio de entrada para o reconhecedor, use o reconhecedor <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A>propriedade.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A> Para obter mais informações sobre o estado de áudio, consulte o <xref:System.Speech.Recognition.AudioState>enumeração.</xref:System.Speech.Recognition.AudioState>       Quando você cria um delegado AudioStateChanged, identifica o método que manipulará o evento. Para associar o evento com o manipulador de eventos, adicione uma instância do representante ao evento. O manipulador de eventos é chamado sempre que o evento ocorre, a menos que você remova o delegado. Para obter mais informações sobre delegados de manipulador de eventos, consulte [eventos e delegados](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example uses a handler for the AudioStateChanged event to write the recognizer's new <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A> to the console each time it changes, using a member of the <xref:System.Speech.Recognition.AudioState> enumeration.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a grammar.  \n        Choices animals = new Choices(new string[] { \"cow\", \"pig\", \"goat\" });  \n        GrammarBuilder farm = new GrammarBuilder(\"On this farm he had a\");  \n        farm.Append(animals);  \n        Grammar farmAnimals = new Grammar(farm);  \n        farmAnimals.Name = \"Farm\";  \n        recognizer.LoadGrammar(farmAnimals);  \n  \n        // Attach event handlers.  \n        recognizer.AudioStateChanged +=  \n          new EventHandler<AudioStateChangedEventArgs>(recognizer_AudioStateChanged);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start recognition.  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null && e.Result.Text != null)  \n      {  \n        Console.WriteLine();  \n        Console.WriteLine(\"  Recognized text =  {0}\", e.Result.Text);  \n        Console.WriteLine();  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  Recognized text not available.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Done.\");  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the AudioStateChanged event.  \n    static void recognizer_AudioStateChanged(object sender, AudioStateChangedEventArgs e)  \n    {  \n      Console.WriteLine(\"The new audio state is: \" + e.AudioState);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs> AudioStateChanged;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioStateChangedEventArgs}
      description: "A ser adicionado."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout
  id: BabbleTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: BabbleTimeout
  nameWithType: SpeechRecognitionEngine.BabbleTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Obtém ou define o intervalo de tempo durante o qual um <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> aceita entrada contendo apenas ruídos de fundo, antes de finalizar o reconhecimento."
  remarks: "Cada reconhecedor de fala tem um algoritmo para distinguir entre silêncio e fala. O reconhecedor classifica como ruídos de fundo qualquer não silêncio de entrada que não correspondem à regra inicial de qualquer um do reconhecedor carregados e habilitados gramáticas de reconhecimento de fala. Se o reconhecedor recebe apenas ruídos de fundo e silêncio dentro do intervalo de tempo limite de Diafonia Múltipla, o reconhecedor finaliza a operação reconhecimento.      -Para operações assíncronas de reconhecimento, gera o reconhecedor de <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>evento, onde o <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A?displayProperty=fullName>é de propriedade `true`e o <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName>é de propriedade `null`.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>      -Para operações síncronas reconhecimento e emulação, retorna o reconhecedor `null`, em vez de <xref:System.Speech.Recognition.RecognitionResult>.</xref:System.Speech.Recognition.RecognitionResult> válido       Se o período de tempo limite de Diafonia Múltipla é definido como 0, o reconhecedor não executa uma verificação de tempo limite de Diafonia Múltipla. O intervalo de tempo limite pode ser qualquer valor negativo. O padrão é 0 segundos."
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition that sets the BabbleTimeout and <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> properties of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> before initiating speech recognition. Handlers for the speech recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> events output event information to the console to demonstrate how the <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> properties of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> affect recognition operations.  \n  \n```c#  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        // Load a Grammar object.  \n        recognizer.LoadGrammar(CreateServicesGrammar(\"FindServices\"));  \n  \n        // Add event handlers.  \n        recognizer.AudioStateChanged +=  \n          new EventHandler<AudioStateChangedEventArgs>(  \n            AudioStateChangedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(3);  \n        recognizer.BabbleTimeout = TimeSpan.FromSeconds(2);  \n        recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1);  \n        recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.5);  \n  \n        Console.WriteLine(\"BabbleTimeout: {0}\", recognizer.BabbleTimeout);  \n        Console.WriteLine(\"InitialSilenceTimeout: {0}\", recognizer.InitialSilenceTimeout);  \n        Console.WriteLine(\"EndSilenceTimeout: {0}\", recognizer.EndSilenceTimeout);  \n        Console.WriteLine(\"EndSilenceTimeoutAmbiguous: {0}\", recognizer.EndSilenceTimeoutAmbiguous);  \n        Console.WriteLine();  \n  \n        // Start asynchronous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Single);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Create a grammar and build it into a Grammar object.   \n    static Grammar CreateServicesGrammar(string grammarName)  \n    {  \n  \n      // Create a grammar for finding services in different cities.  \n      Choices services = new Choices(new string[] { \"restaurants\", \"hotels\", \"gas stations\" });  \n      Choices cities = new Choices(new string[] { \"Seattle\", \"Boston\", \"Dallas\" });  \n  \n      GrammarBuilder findServices = new GrammarBuilder(\"Find\");  \n      findServices.Append(services);  \n      findServices.Append(\"near\");  \n      findServices.Append(cities);  \n  \n      // Create a Grammar object from the GrammarBuilder..  \n      Grammar servicesGrammar = new Grammar(findServices);  \n      servicesGrammar.Name = (\"FindServices\");  \n      return servicesGrammar;  \n    }  \n  \n    // Handle the AudioStateChanged event.  \n    static void AudioStateChangedHandler(  \n      object sender, AudioStateChangedEventArgs e)  \n    {  \n      Console.WriteLine(\"AudioStateChanged ({0}): {1}\",  \n        DateTime.Now.ToString(\"mm:ss.f\"), e.AudioState);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"RecognizeCompleted ({0}):\",  \n        DateTime.Now.ToString(\"mm:ss.f\"));  \n  \n      string resultText;  \n      if (e.Result != null) { resultText = e.Result.Text; }  \n      else { resultText = \"<null>\"; }  \n  \n      Console.WriteLine(  \n        \" BabbleTimeout: {0}; InitialSilenceTimeout: {1}; Result text: {2}\",  \n        e.BabbleTimeout, e.InitialSilenceTimeout, resultText);  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\" Exception message: \", e.Error.Message);  \n      }  \n  \n      // Start the next asynchronous recognition operation.  \n      ((SpeechRecognitionEngine)sender).RecognizeAsync(RecognizeMode.Single);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public TimeSpan BabbleTimeout { get; set; }
    return:
      type: System.TimeSpan
      description: "A duração do intervalo de tempo."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "Essa propriedade é definida como menor que 0 segundos."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Dispose
  id: Dispose
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: Dispose()
  nameWithType: SpeechRecognitionEngine.Dispose()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Dispose()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Descarta o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> objeto."
  syntax:
    content: public void Dispose ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.Dispose*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Dispose(System.Boolean)
  id: Dispose(System.Boolean)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: Dispose(Boolean)
  nameWithType: SpeechRecognitionEngine.Dispose(Boolean)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Dispose(Boolean)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Descarta o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> recursos de objeto e as versões usados durante a sessão."
  syntax:
    content: protected virtual void Dispose (bool disposing);
    parameters:
    - id: disposing
      type: System.Boolean
      description: "<xref uid=&quot;langword_csharp_true&quot; name=&quot;true&quot; href=&quot;&quot;></xref>para liberar recursos gerenciados e não gerenciados; <xref uid=&quot;langword_csharp_false&quot; name=&quot;false&quot; href=&quot;&quot;> </xref> para liberar apenas recursos não gerenciados."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.Dispose*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)
  id: EmulateRecognize(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognize(String)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Emula a entrada de uma frase para o reconhecedor de fala, usando texto em vez de áudio para o reconhecimento de fala síncrona."
  remarks: "A gera do reconhecedor de fala a <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, e <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>eventos como se a operação de reconhecimento não é emulada.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>       Os identificadores que acompanham o Vista e Windows 7 Ignorar maiusculas e minúsculas e largura de caracteres ao aplicar regras de gramática para a expressão de entrada. Para obter mais informações sobre esse tipo de comparação, consulte a <xref:System.Globalization.CompareOptions>enumeração de valores <xref:System.Globalization.CompareOptions>e <xref:System.Globalization.CompareOptions>.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> Os identificadores também ignoram linhas novas e espaço em branco extra e tratam a pontuação como entrada literal."
  example:
  - "The code example below is part of a console application that demonstrates emulated input, the associated recognition results, and the associated events raised by the speech recognizer. The example generates the following output.  \n  \n```  \nTestRecognize(\"Smith\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Smith; Text = Smith  \n...Recognition result text = Smith  \n  \nTestRecognize(\"Jones\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Jones; Text = Jones  \n...Recognition result text = Jones  \n  \nTestRecognize(\"Mister\")...  \n SpeechDetected event raised.  \n SpeechHypothesized event raised.  \n  Grammar = Smith; Text = mister  \n SpeechRecognitionRejected event raised.  \n  Grammar = <not available>; Text =  \n...No recognition result.  \n  \nTestRecognize(\"Mister Smith\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Smith; Text = mister Smith  \n...Recognition result text = mister Smith  \n  \npress any key to exit...  \n```  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \n  \nnamespace Sre_EmulateRecognize  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n  \n        // Load grammars.  \n        recognizer.LoadGrammar(CreateNameGrammar(\"Smith\"));  \n        recognizer.LoadGrammar(CreateNameGrammar(\"Jones\"));  \n  \n        // Disable audio input to the recognizer.  \n        recognizer.SetInputToNull();  \n  \n        // Add handlers for events raised by the EmulateRecognize method.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n  \n        // Start four synchronous emulated recognition operations.  \n        TestRecognize(recognizer, \"Smith\");  \n        TestRecognize(recognizer, \"Jones\");  \n        TestRecognize(recognizer, \"Mister\");  \n        TestRecognize(recognizer, \"Mister Smith\");  \n      }  \n  \n      Console.WriteLine(\"press any key to exit...\");  \n      Console.ReadKey(true);  \n    }  \n  \n    // Create a simple name grammar.  \n    // Set the grammar name to the surname.  \n    private static Grammar CreateNameGrammar(string surname)  \n    {  \n      GrammarBuilder builder = new GrammarBuilder(\"mister\", 0, 1);  \n      builder.Append(surname);  \n  \n      Grammar nameGrammar = new Grammar(builder);  \n      nameGrammar.Name = surname;  \n  \n      return nameGrammar;  \n    }  \n  \n    // Send emulated input to the recognizer for synchronous recognition.  \n    private static void TestRecognize(  \n      SpeechRecognitionEngine recognizer, string input)  \n    {  \n      Console.WriteLine(\"TestRecognize(\\\"{0}\\\")...\", input);  \n      RecognitionResult result =  \n        recognizer.EmulateRecognize(input,CompareOptions.IgnoreCase);  \n      if (result != null)  \n      {  \n        Console.WriteLine(\"...Recognition result text = {0}\",  \n          result.Text ?? \"<null>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"...No recognition result.\");  \n      }  \n      Console.WriteLine();  \n    }  \n  \n    static void SpeechDetectedHandler(  \n      object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechDetected event raised.\");  \n    }  \n  \n    // Handle events.  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechHypothesized event raised.\");  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          e.Result.Grammar.Name ?? \"<none>\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechRecognitionRejected event raised.\");  \n      if (e.Result != null)  \n      {  \n        string grammarName;  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name ?? \"<none>\";  \n        }  \n        else  \n        {  \n          grammarName = \"<not available>\";  \n        }  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          grammarName, e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechRecognized event raised.\");  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          e.Result.Grammar.Name ?? \"<none>\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText);
    parameters:
    - id: inputText
      type: System.String
      description: "A entrada para a operação de reconhecimento."
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "O resultado da operação de reconhecimento, ou <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> se a operação não for bem-sucedida ou o reconhecedor não está habilitado."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "O reconhecedor não tem nenhuma gramática de reconhecimento de fala carregada."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>inputText</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>inputText</code>é a cadeia de caracteres vazia (&quot;&quot;)."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  id: EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Emula a entrada de palavras específicas para o reconhecedor de fala, usando texto em vez de áudio para reconhecimento de fala síncrona e especifica como o reconhecedor trata Unicode comparação entre as palavras e as gramáticas de reconhecimento de fala carregado."
  remarks: "A gera do reconhecedor de fala a <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, e <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>eventos como se a operação de reconhecimento não é emulada.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>       O reconhecedor usa `compareOptions` quando ele aplica regras da gramática a frase de entrada. Os identificadores que acompanham o Vista e Windows 7 Ignorar maiusculas e minúsculas, se o <xref:System.Globalization.CompareOptions>ou <xref:System.Globalization.CompareOptions>valor está presente.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> O reconhecedor sempre ignora a largura de caractere e nunca ignora o tipo Kana. O reconhecedor também ignora novas linhas e espaço em branco extra e trata pontuação como entrada literal. Para obter mais informações sobre o tipo Kana e de largura de caractere, consulte o <xref:System.Globalization.CompareOptions>enumeração.</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: wordUnits
      type: System.Speech.Recognition.RecognizedWordUnit[]
      description: "Uma matriz de unidades do word que contém a entrada para a operação de reconhecimento."
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "Uma combinação bit a bit dos valores de enumeração que descreve o tipo de comparação a ser usado para a operação de reconhecimento emulado."
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "O resultado da operação de reconhecimento, ou <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> se a operação não for bem-sucedida ou o reconhecedor não está habilitado."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "O reconhecedor não tem nenhuma gramática de reconhecimento de fala carregada."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>wordUnits</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>wordUnits</code>contém um ou mais <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> elementos."
  - type: System.NotSupportedException
    commentId: T:System.NotSupportedException
    description: "<code>compareOptions</code>contém o <xref:System.Globalization.CompareOptions>, <xref:System.Globalization.CompareOptions>, ou <xref:System.Globalization.CompareOptions> sinalizador."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  id: EmulateRecognize(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognize(String,CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(String,CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Emula a entrada de uma frase para o reconhecedor de fala, usando texto em vez de áudio para reconhecimento de fala síncrona e especifica como o reconhecedor trata a comparação Unicode entre a frase e as gramáticas de reconhecimento de fala carregado."
  remarks: "A gera do reconhecedor de fala a <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, e <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>eventos como se a operação de reconhecimento não é emulada.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>       O reconhecedor usa `compareOptions` quando ele aplica regras da gramática a frase de entrada. Os identificadores que acompanham o Vista e Windows 7 Ignorar maiusculas e minúsculas, se o <xref:System.Globalization.CompareOptions>ou <xref:System.Globalization.CompareOptions>valor está presente.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> O reconhecedor sempre ignora a largura de caractere e nunca ignora o tipo Kana. O reconhecedor também ignora novas linhas e espaço em branco extra e trata pontuação como entrada literal. Para obter mais informações sobre o tipo Kana e de largura de caractere, consulte o <xref:System.Globalization.CompareOptions>enumeração.</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: inputText
      type: System.String
      description: "A frase de entrada para a operação de reconhecimento."
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "Uma combinação bit a bit dos valores de enumeração que descreve o tipo de comparação a ser usado para a operação de reconhecimento emulado."
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "O resultado da operação de reconhecimento, ou <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> se a operação não for bem-sucedida ou o reconhecedor não está habilitado."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "O reconhecedor não tem nenhuma gramática de reconhecimento de fala carregada."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>inputText</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>inputText</code>é a cadeia de caracteres vazia (&quot;&quot;)."
  - type: System.NotSupportedException
    commentId: T:System.NotSupportedException
    description: "<code>compareOptions</code>contém o <xref:System.Globalization.CompareOptions>, <xref:System.Globalization.CompareOptions>, ou <xref:System.Globalization.CompareOptions> sinalizador."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)
  id: EmulateRecognizeAsync(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognizeAsync(String)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Emula a entrada de uma frase para o reconhecedor de fala, usando texto em vez de áudio para o reconhecimento de fala assíncrona."
  remarks: "A gera do reconhecedor de fala a <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, e <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>eventos como se a operação de reconhecimento não é emulada.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> Quando o reconhecedor conclui a operação de reconhecimento assíncrona, ela gera o <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>evento.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>       Os identificadores que acompanham o Vista e Windows 7 Ignorar maiusculas e minúsculas e largura de caracteres ao aplicar regras de gramática para a expressão de entrada. Para obter mais informações sobre esse tipo de comparação, consulte a <xref:System.Globalization.CompareOptions>enumeração de valores <xref:System.Globalization.CompareOptions>e <xref:System.Globalization.CompareOptions>.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> Os identificadores também ignoram linhas novas e espaço em branco extra e tratam a pontuação como entrada literal."
  example:
  - "The code example below is part of a console application that demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer. The example generates the following output.  \n  \n```  \n  \nTestRecognizeAsync(\"Smith\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Smith; Text = Smith  \n EmulateRecognizeCompleted event raised.  \n  Grammar = Smith; Text = Smith  \n Done.  \n  \nTestRecognizeAsync(\"Jones\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Jones; Text = Jones  \n EmulateRecognizeCompleted event raised.  \n  Grammar = Jones; Text = Jones  \n Done.  \n  \nTestRecognizeAsync(\"Mister\")...  \n SpeechDetected event raised.  \n SpeechHypothesized event raised.  \n  Grammar = Smith; Text = mister  \n SpeechRecognitionRejected event raised.  \n  Grammar = <not available>; Text =  \n EmulateRecognizeCompleted event raised.  \n  No recognition result available.  \n Done.  \n  \nTestRecognizeAsync(\"Mister Smith\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Smith; Text = mister Smith  \n EmulateRecognizeCompleted event raised.  \n  Grammar = Smith; Text = mister Smith  \n Done.  \n  \npress any key to exit...  \n```  \n  \n```c#  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SreEmulateRecognizeAsync  \n{  \n  class Program  \n  {  \n    // Indicate when an asynchronous operation is finished.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        // Load grammars.  \n        recognizer.LoadGrammar(CreateNameGrammar(\"Smith\"));  \n        recognizer.LoadGrammar(CreateNameGrammar(\"Jones\"));  \n  \n        // Configure the audio input.  \n        recognizer.SetInputToNull();  \n  \n        // Add event handlers for the events raised by the  \n        // EmulateRecognizeAsync method.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHander);  \n  \n        // Start four asynchronous emulated recognition operations.  \n        TestRecognizeAsync(recognizer, \"Smith\");  \n        TestRecognizeAsync(recognizer, \"Jones\");  \n        TestRecognizeAsync(recognizer, \"Mister\");  \n        TestRecognizeAsync(recognizer, \"Mister Smith\");  \n      }  \n  \n      Console.WriteLine(\"press any key to exit...\");  \n      Console.ReadKey(true);  \n    }  \n  \n    // Create a simple name grammar.  \n    // Set the grammar name to the surname.  \n    private static Grammar CreateNameGrammar(string surname)  \n    {  \n      GrammarBuilder builder = new GrammarBuilder(\"mister\", 0, 1);  \n      builder.Append(surname);  \n  \n      Grammar nameGrammar = new Grammar(builder);  \n      nameGrammar.Name = surname;  \n  \n      return nameGrammar;  \n    }  \n  \n    // Send emulated input to the recognizer for asynchronous  \n    // recognition.  \n    private static void TestRecognizeAsync(  \n      SpeechRecognitionEngine recognizer, string input)  \n    {  \n      completed = false;  \n  \n      Console.WriteLine(\"TestRecognizeAsync(\\\"{0}\\\")...\", input);  \n      recognizer.EmulateRecognizeAsync(input);  \n  \n      // Wait for the operation to complete.  \n      while (!completed)  \n      {  \n        Thread.Sleep(333);  \n      }  \n  \n      Console.WriteLine(\" Done.\");  \n      Console.WriteLine();  \n    }  \n  \n    static void SpeechDetectedHandler(  \n      object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechDetected event raised.\");  \n    }  \n  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechHypothesized event raised.\");  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          e.Result.Grammar.Name ?? \"<none>\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  \n    // Handle events.  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechRecognitionRejected event raised.\");  \n      if (e.Result != null)  \n      {  \n        string grammarName;  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name ?? \"<none>\";  \n        }  \n        else  \n        {  \n          grammarName = \"<not available>\";  \n        }  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          grammarName, e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechRecognized event raised.\");  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          e.Result.Grammar.Name ?? \"<none>\", e.Result.Text );  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  \n    static void EmulateRecognizeCompletedHander(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\" EmulateRecognizeCompleted event raised.\");  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"  {0} exception encountered: {1}:\",  \n          e.Error.GetType().Name, e.Error.Message);  \n      }  \n      else if (e.Cancelled)  \n      {  \n        Console.WriteLine(\"  Operation cancelled.\");  \n      }  \n      else if (e.Result != null)  \n      {  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          e.Result.Grammar.Name ?? \"<none>\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void EmulateRecognizeAsync (string inputText);
    parameters:
    - id: inputText
      type: System.String
      description: "A entrada para a operação de reconhecimento."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "O reconhecedor não tem nenhuma gramática de reconhecimento de fala carregada ou o reconhecedor tem uma operação assíncrona reconhecimento que ainda não está completa."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>inputText</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>inputText</code>é a cadeia de caracteres vazia (&quot;&quot;)."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  id: EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Emula a entrada de palavras específicas para o reconhecedor de fala, usando uma matriz de <xref href=&quot;System.Speech.Recognition.RecognizedWordUnit&quot;> </xref> objetos no lugar de áudio para o reconhecimento de fala assíncrona e especifica como o reconhecedor trata Unicode comparação entre as palavras e as gramáticas de reconhecimento de fala carregado."
  remarks: "A gera do reconhecedor de fala a <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, e <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>eventos como se a operação de reconhecimento não é emulada.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> Quando o reconhecedor conclui a operação de reconhecimento assíncrona, ela gera o <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>evento.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>       O reconhecedor usa `compareOptions` quando ele aplica regras da gramática a frase de entrada. Os identificadores que acompanham o Vista e Windows 7 Ignorar maiusculas e minúsculas, se o <xref:System.Globalization.CompareOptions>ou <xref:System.Globalization.CompareOptions>valor está presente.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> Os identificadores sempre ignorar a largura de caractere e nunca ignorar o tipo Kana. Os identificadores também ignoram linhas novas e espaço em branco extra e tratam a pontuação como entrada literal. Para obter mais informações sobre o tipo Kana e de largura de caractere, consulte o <xref:System.Globalization.CompareOptions>enumeração.</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public void EmulateRecognizeAsync (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: wordUnits
      type: System.Speech.Recognition.RecognizedWordUnit[]
      description: "Uma matriz de unidades do word que contém a entrada para a operação de reconhecimento."
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "Uma combinação bit a bit dos valores de enumeração que descreve o tipo de comparação a ser usado para a operação de reconhecimento emulado."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "O reconhecedor não tem nenhuma gramática de reconhecimento de fala carregada ou o reconhecedor tem uma operação assíncrona reconhecimento que ainda não está completa."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>wordUnits</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>wordUnits</code>contém um ou mais <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> elementos."
  - type: System.NotSupportedException
    commentId: T:System.NotSupportedException
    description: "<code>compareOptions</code>contém o <xref:System.Globalization.CompareOptions>, <xref:System.Globalization.CompareOptions>, ou <xref:System.Globalization.CompareOptions> sinalizador."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  id: EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognizeAsync(String,CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(String,CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Emula a entrada de uma frase para o reconhecedor de fala, usando texto em vez de áudio para reconhecimento de fala assíncrona e especifica como o reconhecedor trata a comparação Unicode entre a frase e as gramáticas de reconhecimento de fala carregado."
  remarks: "A gera do reconhecedor de fala a <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, e <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>eventos como se a operação de reconhecimento não é emulada.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> Quando o reconhecedor conclui a operação de reconhecimento assíncrona, ela gera o <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>evento.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>       O reconhecedor usa `compareOptions` quando ele aplica regras da gramática a frase de entrada. Os identificadores que acompanham o Vista e Windows 7 Ignorar maiusculas e minúsculas, se o <xref:System.Globalization.CompareOptions>ou <xref:System.Globalization.CompareOptions>valor está presente.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> Os identificadores sempre ignorar a largura de caractere e nunca ignorar o tipo Kana. Os identificadores também ignoram linhas novas e espaço em branco extra e tratam a pontuação como entrada literal. Para obter mais informações sobre o tipo Kana e de largura de caractere, consulte o <xref:System.Globalization.CompareOptions>enumeração.</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public void EmulateRecognizeAsync (string inputText, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: inputText
      type: System.String
      description: "A frase de entrada para a operação de reconhecimento."
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "Uma combinação bit a bit dos valores de enumeração que descreve o tipo de comparação a ser usado para a operação de reconhecimento emulado."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "O reconhecedor não tem nenhuma gramática de reconhecimento de fala carregada ou o reconhecedor tem uma operação assíncrona reconhecimento que ainda não está completa."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>inputText</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>inputText</code>é a cadeia de caracteres vazia (&quot;&quot;)."
  - type: System.NotSupportedException
    commentId: T:System.NotSupportedException
    description: "<code>compareOptions</code>contém o <xref:System.Globalization.CompareOptions>, <xref:System.Globalization.CompareOptions>, ou <xref:System.Globalization.CompareOptions> sinalizador."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted
  id: EmulateRecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognizeCompleted
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Gerado quando o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> Finaliza uma operação assíncrona de reconhecimento de entrada emulada."
  remarks: "Cada <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>método começa uma operação assíncrona reconhecimento.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> O <xref:System.Speech.Recognition.SpeechRecognitionEngine>gera o evento EmulateRecognizeCompleted quando ele finaliza a operação assíncrona.</xref:System.Speech.Recognition.SpeechRecognitionEngine>       O <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>operação pode gerar o <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, e <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>eventos.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> O evento EmulateRecognizeCompleted é o último evento desse tipo que o reconhecedor gera para uma determinada operação.       Se o reconhecimento emulado foi bem-sucedida, você pode acessar o resultado de reconhecimento usando um dos seguintes: - o <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A>propriedade no <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>objeto no manipulador para o evento EmulateRecognizeCompleted.</xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs> </xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A>      - <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>propriedade o <xref:System.Speech.Recognition.SpeechRecognizedEventArgs>objeto no manipulador para o <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>evento.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognizedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>       Se o reconhecimento emulado não foi bem-sucedida, o <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>não é gerado e o <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A>será nulo.</xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>       <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>derivado de <xref:System.ComponentModel.AsyncCompletedEventArgs>.</xref:System.ComponentModel.AsyncCompletedEventArgs></xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>       <xref:System.Speech.Recognition.SpeechRecognizedEventArgs>derivado de <xref:System.Speech.Recognition.RecognitionEventArgs>.</xref:System.Speech.Recognition.RecognitionEventArgs></xref:System.Speech.Recognition.SpeechRecognizedEventArgs>       Quando você cria um delegado EmulateRecognizeCompleted, identifica o método que manipulará o evento. Para associar o evento com o manipulador de eventos, adicione uma instância do representante ao evento. O manipulador de eventos é chamado sempre que o evento ocorre, a menos que você remova o delegado. Para obter mais informações sobre delegados de manipulador de eventos, consulte [eventos e delegados](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace InProcessRecognizer  \n{  \n  class Program  \n  {  \n    // Indicate whether the asynchronous emulate recognition  \n    // operation has completed.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an instance of an in-process recognizer.  \n      using (SpeechRecognitionEngine recognizer =   \n        new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call mathches the grammar  \n        // and generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call does not match the grammar  \n        // or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Result of 1st call to EmulateRecognizeAsync = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n        Console.WriteLine();  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  \n    // Handle the EmulateRecognizeCompleted event.  \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"Result of 2nd call to EmulateRecognizeAsync = No result generated.\");  \n      }  \n  \n      // Indicate the asynchronous operation is complete.  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs> EmulateRecognizeCompleted;
    return:
      type: System.EventHandler{System.Speech.Recognition.EmulateRecognizeCompletedEventArgs}
      description: "A ser adicionado."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout
  id: EndSilenceTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EndSilenceTimeout
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Obtém ou define o intervalo de silêncio que o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> aceitará no final da entrada ambíguo antes de concluir uma operação de reconhecimento."
  remarks: "O reconhecedor de fala usa esse intervalo de tempo limite quando a entrada de reconhecimento é ambígua. Por exemplo, para uma gramática de reconhecimento de fala que oferece suporte ao reconhecimento do &quot;novo jogo.&quot; ou &quot;novo jogo&quot;, &quot;novo jogo,&quot; é uma entrada ambígua, e &quot;novo jogo&quot; é uma entrada ambígua.       Essa propriedade determina quanto tempo o reconhecimento de fala aguardará entrada adicional antes de concluir uma operação de reconhecimento. O intervalo de tempo limite pode ser de 0 segundos para 10 segundos, inclusivos. O padrão é de 150 milissegundos.       Para definir o intervalo de tempo limite para a entrada ambíguo, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>propriedade.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>"
  syntax:
    content: public TimeSpan EndSilenceTimeout { get; set; }
    return:
      type: System.TimeSpan
      description: "A duração do intervalo de silêncio."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "Essa propriedade é definida como menor que 0 segundos ou maior que 10 segundos."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  id: EndSilenceTimeoutAmbiguous
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EndSilenceTimeoutAmbiguous
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Obtém ou define o intervalo de silêncio que o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> aceitará no final da entrada ambíguo antes de concluir uma operação de reconhecimento."
  remarks: "O reconhecedor de fala usa esse intervalo de tempo limite quando a entrada de reconhecimento é ambígua. Por exemplo, para uma gramática de reconhecimento de fala que oferece suporte ao reconhecimento do &quot;novo jogo.&quot; ou &quot;novo jogo&quot;, &quot;novo jogo,&quot; é uma entrada ambígua, e &quot;novo jogo&quot; é uma entrada ambígua.       Essa propriedade determina quanto tempo o reconhecimento de fala aguardará entrada adicional antes de concluir uma operação de reconhecimento. O intervalo de tempo limite pode ser de 0 segundos para 10 segundos, inclusivos. O padrão é 500 milissegundos.       Para definir o intervalo de tempo limite para a entrada não ambígua, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>propriedade.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>"
  syntax:
    content: public TimeSpan EndSilenceTimeoutAmbiguous { get; set; }
    return:
      type: System.TimeSpan
      description: "A duração do intervalo de silêncio."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "Essa propriedade é definida como menor que 0 segundos ou maior que 10 segundos."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Grammars
  id: Grammars
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: Grammars
  nameWithType: SpeechRecognitionEngine.Grammars
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Grammars
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Obtém uma coleção do <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> objetos que são carregados na <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> instância."
  remarks: ''
  example:
  - "The following example outputs information to the console for each speech recognition grammar that is currently loaded by a speech recognizer.  \n  \n> [!IMPORTANT]\n>  Copy the grammar collection to avoid errors if the collection is modified while this method enumerates the elements of the collection.  \n  \n```c#  \n  \nprivate static void ListGrammars(SpeechRecognitionEngine recognizer)  \n{  \n  string qualifier;  \n  List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  \n  foreach (Grammar g in grammars)  \n  {  \n    qualifier = (g.Enabled) ? \"enabled\" : \"disabled\";  \n  \n    Console.WriteLine(\"Grammar {0} is loaded and is {1}.\",  \n      g.Name, qualifier);  \n  }  \n}  \n```"
  syntax:
    content: public System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.Grammar> Grammars { get; }
    return:
      type: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.Grammar}
      description: "A coleção de <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> objetos."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.Grammars*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout
  id: InitialSilenceTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: InitialSilenceTimeout
  nameWithType: SpeechRecognitionEngine.InitialSilenceTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Obtém ou define o intervalo de tempo durante o qual um <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> aceita entrado silêncio somente contendo antes de finalizar o reconhecimento."
  remarks: "Cada reconhecedor de fala tem um algoritmo para distinguir entre silêncio e fala. Se a entrada do reconhecedor for silêncio durante o período de tempo limite de silêncio inicial, o reconhecedor finaliza a operação reconhecimento.      -Para operações assíncronas de reconhecimento e emulação, gera o reconhecedor de <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>evento, onde o <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A?displayProperty=fullName>é de propriedade `true`e o <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName>é de propriedade `null`.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>      -Para operações síncronas reconhecimento e emulação, retorna o reconhecedor `null`, em vez de <xref:System.Speech.Recognition.RecognitionResult>.</xref:System.Speech.Recognition.RecognitionResult> válido       Se o intervalo de tempo limite de silêncio inicial é definido como 0, o reconhecedor não executa uma verificação de tempo limite de silêncio inicial. O intervalo de tempo limite pode ser qualquer valor negativo. O padrão é 0 segundos."
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example sets the <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> and InitialSilenceTimeout properties of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> before initiating speech recognition. Handlers for the speech recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> events output event information to the console to demonstrate how the InitialSilenceTimeout properties of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> properties affect recognition operations.  \n  \n```c#  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        // Load a Grammar object.  \n        recognizer.LoadGrammar(CreateServicesGrammar(\"FindServices\"));  \n  \n        // Add event handlers.  \n        recognizer.AudioStateChanged +=  \n          new EventHandler<AudioStateChangedEventArgs>(  \n            AudioStateChangedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(3);  \n        recognizer.BabbleTimeout = TimeSpan.FromSeconds(2);  \n        recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1);  \n        recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.5);  \n  \n        Console.WriteLine(\"BabbleTimeout: {0}\", recognizer.BabbleTimeout);  \n        Console.WriteLine(\"InitialSilenceTimeout: {0}\", recognizer.InitialSilenceTimeout);  \n        Console.WriteLine(\"EndSilenceTimeout: {0}\", recognizer.EndSilenceTimeout);  \n        Console.WriteLine(\"EndSilenceTimeoutAmbiguous: {0}\", recognizer.EndSilenceTimeoutAmbiguous);  \n        Console.WriteLine();  \n  \n        // Start asynchronous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Single);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Create a grammar and build it into a Grammar object.   \n    static Grammar CreateServicesGrammar(string grammarName)  \n    {  \n  \n      // Create a grammar for finding services in different cities.  \n      Choices services = new Choices(new string[] { \"restaurants\", \"hotels\", \"gas stations\" });  \n      Choices cities = new Choices(new string[] { \"Seattle\", \"Boston\", \"Dallas\" });  \n  \n      GrammarBuilder findServices = new GrammarBuilder(\"Find\");  \n      findServices.Append(services);  \n      findServices.Append(\"near\");  \n      findServices.Append(cities);  \n  \n      // Create a Grammar object from the GrammarBuilder..  \n      Grammar servicesGrammar = new Grammar(findServices);  \n      servicesGrammar.Name = (\"FindServices\");  \n      return servicesGrammar;  \n    }  \n  \n    // Handle the AudioStateChanged event.  \n    static void AudioStateChangedHandler(  \n      object sender, AudioStateChangedEventArgs e)  \n    {  \n      Console.WriteLine(\"AudioStateChanged ({0}): {1}\",  \n        DateTime.Now.ToString(\"mm:ss.f\"), e.AudioState);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"RecognizeCompleted ({0}):\",  \n        DateTime.Now.ToString(\"mm:ss.f\"));  \n  \n      string resultText;  \n      if (e.Result != null) { resultText = e.Result.Text; }  \n      else { resultText = \"<null>\"; }  \n  \n      Console.WriteLine(  \n        \" BabbleTimeout: {0}; InitialSilenceTimeout: {1}; Result text: {2}\",  \n        e.BabbleTimeout, e.InitialSilenceTimeout, resultText);  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\" Exception message: \", e.Error.Message);  \n      }  \n  \n      // Start the next asynchronous recognition operation.  \n      ((SpeechRecognitionEngine)sender).RecognizeAsync(RecognizeMode.Single);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public TimeSpan InitialSilenceTimeout { get; set; }
    return:
      type: System.TimeSpan
      description: "A duração do intervalo de silêncio."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "Essa propriedade é definida como menor que 0 segundos."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers
  id: InstalledRecognizers
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: InstalledRecognizers()
  nameWithType: SpeechRecognitionEngine.InstalledRecognizers()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Retorna informações de todos os identificadores de fala instalados no sistema atual."
  remarks: "Para obter informações sobre o identificador atual, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A>propriedade.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example uses the collection returned by the InstalledRecognizers method to find a speech recognizer that supports the English language.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Select a speech recognizer that supports English.  \n      RecognizerInfo info = null;  \n      foreach (RecognizerInfo ri in SpeechRecognitionEngine.InstalledRecognizers())  \n      {  \n        if (ri.Culture.TwoLetterISOLanguageName.Equals(\"en\"))  \n        {  \n          info = ri;  \n          break;  \n        }  \n      }  \n      if (info == null) return;  \n  \n      // Create the selected recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(info))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public static System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.RecognizerInfo> InstalledRecognizers ();
    parameters: []
    return:
      type: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.RecognizerInfo}
      description: "Uma coleção de somente leitura do <xref href=&quot;System.Speech.Recognition.RecognizerInfo&quot;> </xref> objetos que descrevem os reconhecedores instalados."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)
  id: LoadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: LoadGrammar(Grammar)
  nameWithType: SpeechRecognitionEngine.LoadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Modo síncrono carrega um <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> objeto."
  remarks: "O reconhecedor lança uma exceção se o <xref:System.Speech.Recognition.Grammar>objeto já está carregado, está sendo carregado de forma assíncrona ou falhou ao carregar qualquer reconhecedor.</xref:System.Speech.Recognition.Grammar> Não é possível carregar o mesmo <xref:System.Speech.Recognition.Grammar>objeto em várias instâncias do <xref:System.Speech.Recognition.SpeechRecognitionEngine>.</xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.Grammar> Em vez disso, crie um novo <xref:System.Speech.Recognition.Grammar>objeto para cada <xref:System.Speech.Recognition.SpeechRecognitionEngine>instância.</xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.Grammar>       Se o reconhecedor está em execução, os aplicativos devem usar <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>para pausar o mecanismo de reconhecimento de fala antes do carregamento, descarregamento, habilitar ou desabilitar uma gramática.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>       Quando você carrega uma gramática, ele é habilitado por padrão. Para desabilitar uma gramática carregada, use o <xref:System.Speech.Recognition.Grammar.Enabled%2A>propriedade.</xref:System.Speech.Recognition.Grammar.Enabled%2A>       Para carregar um <xref:System.Speech.Recognition.Grammar>objeto de forma assíncrona, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.Grammar>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example creates a <xref:System.Speech.Recognition.DictationGrammar> and loads it into a speech recognizer.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (  \n      SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void LoadGrammar (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "O objeto de gramática para carregar."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>Grammar</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "<code>Grammar</code>não está em um estado válido."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  id: LoadGrammarAsync(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: LoadGrammarAsync(Grammar)
  nameWithType: SpeechRecognitionEngine.LoadGrammarAsync(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Carrega assincronamente uma gramática de reconhecimento de fala."
  remarks: "Quando o reconhecedor de completa o carregamento um <xref:System.Speech.Recognition.Grammar>do objeto, ele gera um <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted>evento.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted> </xref:System.Speech.Recognition.Grammar> O reconhecedor lança uma exceção se o <xref:System.Speech.Recognition.Grammar>objeto já está carregado, está sendo carregado de forma assíncrona ou falhou ao carregar qualquer reconhecedor.</xref:System.Speech.Recognition.Grammar> Não é possível carregar o mesmo <xref:System.Speech.Recognition.Grammar>objeto em várias instâncias do <xref:System.Speech.Recognition.SpeechRecognitionEngine>.</xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.Grammar> Em vez disso, crie um novo <xref:System.Speech.Recognition.Grammar>objeto para cada <xref:System.Speech.Recognition.SpeechRecognitionEngine>instância.</xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.Grammar>       Se o reconhecedor está em execução, os aplicativos devem usar <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>para pausar o mecanismo de reconhecimento de fala antes do carregamento, descarregamento, habilitar ou desabilitar uma gramática.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>       Quando você carrega uma gramática, ele é habilitado por padrão. Para desabilitar uma gramática carregada, use o <xref:System.Speech.Recognition.Grammar.Enabled%2A>propriedade.</xref:System.Speech.Recognition.Grammar.Enabled%2A>       Para carregar uma gramática de reconhecimento de fala de forma síncrona, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>"
  syntax:
    content: public void LoadGrammarAsync (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "A gramática de reconhecimento de fala para carregar."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>Grammar</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "<code>Grammar</code>não está em um estado válido."
  - type: System.OperationCanceledException
    commentId: T:System.OperationCanceledException
    description: "A operação assíncrona foi cancelada."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted
  id: LoadGrammarCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: LoadGrammarCompleted
  nameWithType: SpeechRecognitionEngine.LoadGrammarCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Gerado quando o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> termina o carregamento assíncrono de um <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> objeto."
  remarks: "O reconhecedor <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>método inicia uma operação assíncrona.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> O <xref:System.Speech.Recognition.SpeechRecognitionEngine>gera esse evento quando concluir a operação.</xref:System.Speech.Recognition.SpeechRecognitionEngine> Para obter o <xref:System.Speech.Recognition.Grammar>objeto que o reconhecedor carregado, use a <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A>propriedade de <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>.</xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs> associado</xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A> </xref:System.Speech.Recognition.Grammar> Para obter atual <xref:System.Speech.Recognition.Grammar>o reconhecedor tiver sido carregado, os objetos usam o reconhecedor <xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A>propriedade.</xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A> </xref:System.Speech.Recognition.Grammar>       Se o reconhecedor está em execução, os aplicativos devem usar <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>para pausar o mecanismo de reconhecimento de fala antes do carregamento, descarregamento, habilitar ou desabilitar uma gramática.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>       Quando você cria um delegado LoadGrammarCompleted, identifica o método que manipulará o evento. Para associar o evento com o manipulador de eventos, adicione uma instância do representante ao evento. O manipulador de eventos é chamado sempre que o evento ocorre, a menos que você remova o delegado. Para obter mais informações sobre delegados de manipulador de eventos, consulte [eventos e delegados](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example creates an in-process speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation. The example constructs a <xref:System.Speech.Recognition.Grammar> object from each of the completed speech recognition grammars, then asynchronously loads the <xref:System.Speech.Recognition.Grammar> objects to the <xref:System.Speech.Recognition.SpeechRecognitionEngine> instance. Handlers for the recognizer's LoadGrammarCompleted and <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> events write to the console the name of the <xref:System.Speech.Recognition.Grammar> object that was used to perform the recognition and the text of the recognition result, respectively.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognitionEngine recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognition engine and set its input.  \n      recognizer = new SpeechRecognitionEngine();  \n      recognizer.SetInputToDefaultAudioDevice();  \n  \n      // Add a handler for the LoadGrammarCompleted event.  \n      recognizer.LoadGrammarCompleted +=  \n        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n      // Add a handler for the SpeechRecognized event.  \n      recognizer.SpeechRecognized +=  \n        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n      // Create the \"yesno\" grammar.  \n      Choices yesChoices = new Choices(new string[] { \"yes\", \"yup\", \"yeah\" });  \n      SemanticResultValue yesValue =  \n          new SemanticResultValue(yesChoices, (bool)true);  \n      Choices noChoices = new Choices(new string[] { \"no\", \"nope\", \"neah\" });  \n      SemanticResultValue noValue =  \n          new SemanticResultValue(noChoices, (bool)false);  \n      SemanticResultKey yesNoKey =  \n          new SemanticResultKey(\"yesno\", new Choices(new GrammarBuilder[] { yesValue, noValue }));  \n      Grammar yesnoGrammar = new Grammar(yesNoKey);  \n      yesnoGrammar.Name = \"yesNo\";  \n  \n      // Create the \"done\" grammar.  \n      Grammar doneGrammar =  \n        new Grammar(new Choices(new string[] { \"done\", \"exit\", \"quit\", \"stop\" }));  \n      doneGrammar.Name = \"Done\";  \n  \n      // Create a dictation grammar.  \n      Grammar dictation = new DictationGrammar();  \n      dictation.Name = \"Dictation\";  \n  \n      // Load grammars to the recognizer.  \n      recognizer.LoadGrammarAsync(yesnoGrammar);  \n      recognizer.LoadGrammarAsync(doneGrammar);  \n      recognizer.LoadGrammarAsync(dictation);  \n  \n      // Start asynchronous, continuous recognition.  \n      recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n      // Keep the console window open.  \n      Console.ReadLine();  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.   \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      string grammarName = e.Grammar.Name;  \n      bool grammarLoaded = e.Grammar.Loaded;  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"LoadGrammar for {0} failed with a {1}.\",  \n        grammarName, e.Error.GetType().Name);  \n  \n        // Add exception handling code here.  \n      }  \n  \n      Console.WriteLine(\"Grammar {0} {1} loaded.\",  \n      grammarName, (grammarLoaded) ? \"is\" : \"is not\");  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar({0}): {1}\", e.Result.Grammar.Name, e.Result.Text);  \n  \n      // Add event handler code here.  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs> LoadGrammarCompleted;
    return:
      type: System.EventHandler{System.Speech.Recognition.LoadGrammarCompletedEventArgs}
      description: "A ser adicionado."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates
  id: MaxAlternates
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: MaxAlternates
  nameWithType: SpeechRecognitionEngine.MaxAlternates
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Obtém ou define o número máximo de resultados do reconhecimento alternativo que o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> retorna para cada operação de reconhecimento."
  remarks: "O <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>propriedade o <xref:System.Speech.Recognition.RecognitionResult>classe contém a coleção de <xref:System.Speech.Recognition.RecognizedPhrase>objetos que representam interpretações possíveis da entrada.</xref:System.Speech.Recognition.RecognizedPhrase> </xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>       O valor padrão para MaxAlternates é 10."
  syntax:
    content: public int MaxAlternates { get; set; }
    return:
      type: System.Int32
      description: "O número de resultados alternativos a ser retornada."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "MaxAlternates é definido como um valor menor que 0."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)
  id: QueryRecognizerSetting(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: QueryRecognizerSetting(String)
  nameWithType: SpeechRecognitionEngine.QueryRecognizerSetting(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Retorna os valores das configurações do reconhecedor."
  remarks: "Configurações do reconhecedor podem conter a cadeia de caracteres, inteiro de 64 bits ou dados de endereço de memória. A tabela a seguir descreve as configurações que são definidas para uma API do Microsoft Speech (SAPI)-reconhecedor compatível. As configurações a seguir devem ter o mesmo intervalo para cada identificador que suporta a configuração. Um identificador compatível com SAPI não é necessário para dar suporte a essas configurações e pode dar suporte a outras configurações.      | Nome | Descrição |   |----------|-----------------|   | `ResourceUsage`| Especifica o consumo de CPU do reconhecedor. O intervalo é de 0 a 100. O valor padrão é 50. |   | `ResponseSpeed`| Indica o comprimento de silêncio no final da entrada ambíguo antes do reconhecedor de fala conclui uma operação de reconhecimento. O intervalo é de 0 a 10.000 milissegundos (ms). Essa configuração corresponde do reconhecedor <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>propriedade.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>  Padrão = 150 ms. |   | `ComplexResponseSpeed`| Indica o comprimento de silêncio no final da entrada ambíguo antes do reconhecedor de fala conclui uma operação de reconhecimento. O intervalo é de 0 a 10.000 ms. Essa configuração corresponde do reconhecedor <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>propriedade.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> Padrão = 500 ms. |   | `AdaptationOn`| Indica se a adaptação do modelo acústico está ON (valor = `1`) ou OFF (valor = `0`). O valor padrão é `1` (ON). |   | `PersistedBackgroundAdaptation`| Indica se a adaptação de plano de fundo é ON (valor = `1`) ou OFF (valor = `0`), e persistir a configuração no registro. O valor padrão é `1` (ON). |       Para atualizar uma configuração do reconhecedor, use uma da <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>métodos.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>"
  example:
  - "The following example is part of a console application that outputs the values for a number of the settings defined for the recognizer that supports the en-US locale. The example generates the following output.  \n  \n```  \nSettings for recognizer MS-1033-80-DESK:  \n  \n  ResourceUsage                  is not supported by this recognizer.  \n  ResponseSpeed                  = 150  \n  ComplexResponseSpeed           = 500  \n  AdaptationOn                   = 1  \n  PersistedBackgroundAdaptation  = 1  \n  \nPress any key to exit...  \n```  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \n  \nnamespace RecognizerSettings  \n{  \n  class Program  \n  {  \n    static readonly string[] settings = new string[] {  \n      \"ResourceUsage\",  \n      \"ResponseSpeed\",  \n      \"ComplexResponseSpeed\",  \n      \"AdaptationOn\",  \n      \"PersistedBackgroundAdaptation\"  \n    };  \n  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        Console.WriteLine(\"Settings for recognizer {0}:\",  \n          recognizer.RecognizerInfo.Name);  \n        Console.WriteLine();  \n  \n        foreach (string setting in settings)  \n        {  \n          try  \n          {  \n            object value = recognizer.QueryRecognizerSetting(setting);  \n            Console.WriteLine(\"  {0,-30} = {1}\", setting, value);  \n          }  \n          catch  \n          {  \n            Console.WriteLine(\"  {0,-30} is not supported by this recognizer.\",  \n              setting);  \n          }  \n        }  \n      }  \n      Console.WriteLine();  \n  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public object QueryRecognizerSetting (string settingName);
    parameters:
    - id: settingName
      type: System.String
      description: "O nome da configuração a retornar."
    return:
      type: System.Object
      description: "O valor da configuração."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>settingName</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>settingName</code>é a cadeia de caracteres vazia (&quot;&quot;)."
  - type: System.Collections.Generic.KeyNotFoundException
    commentId: T:System.Collections.Generic.KeyNotFoundException
    description: "O reconhecedor não tem uma configuração com esse nome."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Recognize
  id: Recognize
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: Recognize()
  nameWithType: SpeechRecognitionEngine.Recognize()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Recognize()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Executa uma operação de reconhecimento de fala síncrona."
  remarks: "Esse método executa uma operação única de reconhecimento. O reconhecedor executa esta operação contra as gramáticas de reconhecimento de fala carregados e habilitados.       Durante uma chamada para esse método, o reconhecedor pode disparar os eventos a seguir:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>  Gerado quando o reconhecedor detecta a entrada, ele pode identificar como fala.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  Gerado quando a entrada cria uma correspondência ambígua com uma das gramáticas ativas.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> Gerado quando o reconhecedor Finaliza uma operação de reconhecimento.       O reconhecedor não gera o <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>evento ao usar esse método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>       Retorna o método reconhecer um <xref:System.Speech.Recognition.RecognitionResult>objeto, ou `null` se a operação não for bem-sucedida.</xref:System.Speech.Recognition.RecognitionResult>       Uma operação síncrona de reconhecimento pode falhar pelos seguintes motivos:-não a fala é detectada antes de expirarem os intervalos de tempo limite para o <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>ou <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>Propriedades.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>      -O mecanismo de reconhecimento detecta fala, mas não encontrar correspondências em qualquer um dos seus carregados e habilitados <xref:System.Speech.Recognition.Grammar>objetos.</xref:System.Speech.Recognition.Grammar>       Para executar o reconhecimento assíncrono, use um do <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>métodos.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example creates a <xref:System.Speech.Recognition.DictationGrammar>, loads it into an in-process speech recognizer, and performs one recognition operation.  \n  \n```  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SynchronousRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Modify the initial silence time-out value.  \n        recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5);  \n  \n        // Start synchronous speech recognition.  \n        RecognitionResult result = recognizer.Recognize();  \n  \n        if (result != null)  \n        {  \n          Console.WriteLine(\"Recognized text = {0}\", result.Text);  \n        }  \n        else  \n        {  \n          Console.WriteLine(\"No recognition result available.\");  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to continue...\");  \n      Console.ReadKey();  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult Recognize ();
    parameters: []
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "O resultado de reconhecimento para a entrada, ou <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> se a operação não for bem-sucedida ou o reconhecedor não está habilitado."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.Recognize*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)
  id: Recognize(System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: Recognize(TimeSpan)
  nameWithType: SpeechRecognitionEngine.Recognize(TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Recognize(TimeSpan)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Executa uma operação de reconhecimento de fala síncrono com um período de tempo limite de silêncio inicial especificado."
  remarks: "Se o mecanismo de reconhecimento de fala detecta fala dentro do intervalo de tempo especificado por `initialSilenceTimeout` argumento, reconhecer executa uma operação de reconhecimento de único e, em seguida, termina.  O `initialSilenceTimeout` parâmetro substitui o reconhecedor <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>propriedade.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>       Durante uma chamada para esse método, o reconhecedor pode disparar os eventos a seguir:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>  Gerado quando o reconhecedor detecta a entrada, ele pode identificar como fala.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  Gerado quando a entrada cria uma correspondência ambígua com uma das gramáticas ativas.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> Gerado quando o reconhecedor Finaliza uma operação de reconhecimento.       O reconhecedor não gera o <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>evento ao usar esse método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>       O <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize>método retorna um <xref:System.Speech.Recognition.RecognitionResult>objeto, ou `null` se a operação não for bem-sucedida.</xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize>       Uma operação síncrona de reconhecimento pode falhar pelos seguintes motivos:-não a fala é detectada antes de expirarem os intervalos de tempo limite para o <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>ou o `initialSilenceTimeout` parâmetro.</xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>      -O mecanismo de reconhecimento detecta fala, mas não encontrar correspondências em qualquer um dos seus carregados e habilitados <xref:System.Speech.Recognition.Grammar>objetos.</xref:System.Speech.Recognition.Grammar>       Para executar o reconhecimento assíncrono, use um do <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>métodos.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example creates a <xref:System.Speech.Recognition.DictationGrammar>, loads it into an in-process speech recognizer, and performs one recognition operation.  \n  \n```c#  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SynchronousRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start synchronous speech recognition.  \n        RecognitionResult result = recognizer.Recognize(TimeSpan.FromSeconds(5));  \n  \n        if (result != null)  \n        {  \n          Console.WriteLine(\"Recognized text = {0}\", result.Text);  \n        }  \n        else  \n        {  \n          Console.WriteLine(\"No recognition result available.\");  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to continue...\");  \n      Console.ReadKey();  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult Recognize (TimeSpan initialSilenceTimeout);
    parameters:
    - id: initialSilenceTimeout
      type: System.TimeSpan
      description: "O intervalo de tempo que o reconhecedor de fala aceita entrada que contém somente silêncio antes de finalizar o reconhecimento."
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "O resultado de reconhecimento para a entrada, ou <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> se a operação não for bem-sucedida ou o reconhecedor não está habilitado."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.Recognize*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync
  id: RecognizeAsync
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizeAsync()
  nameWithType: SpeechRecognitionEngine.RecognizeAsync()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Executa uma operação de reconhecimento de fala único e assíncrona."
  remarks: "Esse método executa uma operação de reconhecimento de único e assíncrona. O reconhecedor executa a operação em relação as gramáticas de reconhecimento de fala carregados e habilitados.       Durante uma chamada para esse método, o reconhecedor pode disparar os eventos a seguir:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>  Gerado quando o reconhecedor detecta a entrada, ele pode identificar como fala.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  Gerado quando a entrada cria uma correspondência ambígua com uma das gramáticas ativas.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> Gerado quando o reconhecedor Finaliza uma operação de reconhecimento.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> Gerado quando um <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>operação concluída.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>       Para recuperar o resultado de uma operação assíncrona de reconhecimento, anexar um manipulador de eventos para o reconhecedor <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>evento.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> O reconhecedor gera esse evento sempre que ele concluir com êxito uma operação de reconhecimento síncronas ou assíncronas. Se o reconhecimento não foi bem-sucedida, o <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A>propriedade <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>objeto, que você pode acessar o manipulador para o <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>eventos, será `null`.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A>       Para executar o reconhecimento síncrono, use um do <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>métodos.</xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic asynchronous speech recognition. The example creates a <xref:System.Speech.Recognition.DictationGrammar>, loads it into an in-process speech recognizer, and performs one asynchronous recognition operation. Event handlers are included to demonstrate the events that the recognizer raises during the operation.  \n  \n```c#  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace AsynchronousRecognition  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition is complete.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        // Create a grammar for choosing cities for a flight.  \n        Choices cities = new Choices(new string[]   \n        { \"Los Angeles\", \"New York\", \"Chicago\", \"San Francisco\", \"Miami\", \"Dallas\" });  \n  \n        GrammarBuilder gb = new GrammarBuilder();  \n        gb.Append(\"I want to fly from\");  \n        gb.Append(cities);  \n        gb.Append(\"to\");  \n        gb.Append(cities);  \n  \n        // Construct a Grammar object and load it to the recognizer.  \n        Grammar cityChooser = new Grammar(gb);  \n        cityChooser.Name = (\"City Chooser\");  \n        recognizer.LoadGrammarAsync(cityChooser);  \n  \n        // Attach event handlers.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Assign input to the recognizer and start an asynchronous  \n        // recognition operation.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        completed = false;  \n        Console.WriteLine(\"Starting asynchronous recognition...\");  \n        recognizer.RecognizeAsync();  \n  \n        // Wait for the operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void SpeechDetectedHandler(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechDetectedHandler:\");  \n      Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechHypothesizedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognitionRejectedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognizedHandler.\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\" In RecognizeCompletedHandler.\");  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(  \n          \" - Error occurred during recognition: {0}\", e.Error);  \n        return;  \n      }  \n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \n      {  \n        Console.WriteLine(  \n          \" - BabbleTimeout = {0}; InitialSilenceTimeout = {1}\",  \n          e.BabbleTimeout, e.InitialSilenceTimeout);  \n        return;  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(  \n          \" - AudioPosition = {0}; InputStreamEnded = {1}\",  \n          e.AudioPosition, e.InputStreamEnded);  \n      }  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(  \n          \" - Grammar = {0}; Text = {1}; Confidence = {2}\",  \n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence);  \n        Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\" - No result.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void RecognizeAsync ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)
  id: RecognizeAsync(System.Speech.Recognition.RecognizeMode)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizeAsync(RecognizeMode)
  nameWithType: SpeechRecognitionEngine.RecognizeAsync(RecognizeMode)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(RecognizeMode)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Executa uma ou mais operações de reconhecimento de fala assíncrona."
  remarks: "Se `mode` é <xref:System.Speech.Recognition.RecognizeMode>, o reconhecedor continua a executar operações assíncronas reconhecimento até que o <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A>ou <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A>método é chamado.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A> </xref:System.Speech.Recognition.RecognizeMode>       Durante uma chamada para esse método, o reconhecedor pode disparar os eventos a seguir:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>  Gerado quando o reconhecedor detecta a entrada, ele pode identificar como fala.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  Gerado quando a entrada cria uma correspondência ambígua com uma das gramáticas ativas.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> Gerado quando o reconhecedor Finaliza uma operação de reconhecimento.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> Gerado quando um <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>operação concluída.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>       Para recuperar o resultado de uma operação assíncrona de reconhecimento, anexar um manipulador de eventos para o reconhecedor <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>evento.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> O reconhecedor gera esse evento sempre que ele concluir com êxito uma operação de reconhecimento síncronas ou assíncronas. Se o reconhecimento não foi bem-sucedida, o <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A>propriedade <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>objeto, que você pode acessar o manipulador para o <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>eventos, será `null`.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A>       Uma operação assíncrona de reconhecimento pode falhar pelos seguintes motivos:-não a fala é detectada antes de expirarem os intervalos de tempo limite para o <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>ou <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>Propriedades.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>      -O mecanismo de reconhecimento detecta fala, mas não encontrar correspondências em qualquer um dos seus carregados e habilitados <xref:System.Speech.Recognition.Grammar>objetos.</xref:System.Speech.Recognition.Grammar>       Para executar o reconhecimento síncrono, use um do <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>métodos.</xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic asynchronous speech recognition. The example creates a <xref:System.Speech.Recognition.DictationGrammar>, loads it into an in-process speech recognizer, and performs multiple asynchronous recognition operations. The asynchronous operations are cancelled after 30 seconds. Event handlers are included to demonstrate the events that the recognizer raises during the operation.  \n  \n```c#  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace AsynchronousRecognition  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition is complete.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        // Create a grammar for choosing cities for a flight.  \n        Choices cities = new Choices(new string[] { \"Los Angeles\", \"New York\", \"Chicago\", \"San Francisco\", \"Miami\", \"Dallas\" });  \n  \n        GrammarBuilder gb = new GrammarBuilder();  \n        gb.Append(\"I want to fly from\");  \n        gb.Append(cities);  \n        gb.Append(\"to\");  \n        gb.Append(cities);  \n  \n        // Construct a Grammar object and load it to the recognizer.  \n        Grammar cityChooser = new Grammar(gb);  \n        cityChooser.Name = (\"City Chooser\");  \n        recognizer.LoadGrammarAsync(cityChooser);  \n  \n        // Attach event handlers.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Assign input to the recognizer and start asynchronous  \n        // recognition.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        completed = false;  \n        Console.WriteLine(\"Starting asynchronous recognition...\");  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Wait 30 seconds, and then cancel asynchronous recognition.  \n        Thread.Sleep(TimeSpan.FromSeconds(30));  \n        recognizer.RecognizeAsyncCancel();  \n  \n        // Wait for the operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void SpeechDetectedHandler(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechDetectedHandler:\");  \n      Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechHypothesizedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognitionRejectedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognizedHandler.\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\" In RecognizeCompletedHandler.\");  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(  \n          \" - Error occurred during recognition: {0}\", e.Error);  \n        return;  \n      }  \n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \n      {  \n        Console.WriteLine(  \n          \" - BabbleTimeout = {0}; InitialSilenceTimeout = {1}\",  \n          e.BabbleTimeout, e.InitialSilenceTimeout);  \n        return;  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(  \n          \" - AudioPosition = {0}; InputStreamEnded = {1}\",  \n          e.AudioPosition, e.InputStreamEnded);  \n      }  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(  \n          \" - Grammar = {0}; Text = {1}; Confidence = {2}\",  \n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence);  \n        Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\" - No result.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void RecognizeAsync (System.Speech.Recognition.RecognizeMode mode);
    parameters:
    - id: mode
      type: System.Speech.Recognition.RecognizeMode
      description: "Indica se deve executar uma ou várias operações de reconhecimento."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel
  id: RecognizeAsyncCancel
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizeAsyncCancel()
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncCancel()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Encerra o reconhecimento assíncrono sem esperar que a operação de reconhecimento atual ser concluída."
  remarks: "Esse método imediatamente finaliza reconhecimento assíncrono. Se a operação assíncrona reconhecimento atual está recebendo a entrada, a entrada será truncada e a conclusão da operação com a entrada existente. Gera o reconhecedor de <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>ou <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>eventos quando uma operação assíncrona foi cancelada e define o <xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A>propriedade do <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>para `true`.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs> </xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> Esse método cancela operações assíncronas iniciadas pelo <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>e <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>métodos.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>       Para interromper o reconhecimento assíncrono sem truncamento de entrada, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A>"
  example:
  - "The following example shows part of a console application that demonstrates the use of the RecognizeAsyncCancel method. The example creates and loads a speech recognition grammar, initiates a continuing asynchronous recognition operation, and then pauses 2 seconds before it cancels the operation. The recognizer receives input from the file, c:\\temp\\audioinput\\sample.wav. Event handlers are included to demonstrate the events that the recognizer raises during the operation.  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace AsynchronousRecognition  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition is complete.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        // Create and load a dictation grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Attach event handlers.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Begin asynchronous recognition from pre-recorded input.  \n        recognizer.SetInputToWaveFile(@\"c:\\temp\\audioinput\\sample.wav\");  \n  \n        completed = false;  \n        Console.WriteLine(\"Begin continuing asynchronous recognition...\");  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Wait 2 seconds and then cancel the recognition operation.  \n        Thread.Sleep(TimeSpan.FromSeconds(2));  \n        recognizer.RecognizeAsyncCancel();  \n  \n        // Wait for the operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void SpeechDetectedHandler(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechDetectedHandler:\");  \n      Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechHypothesizedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognitionRejectedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognizedHandler.\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\" In RecognizeCompletedHandler.\");  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(  \n          \" - Error occurred during recognition: {0}\", e.Error);  \n        return;  \n      }  \n      if (e.Cancelled)  \n      {  \n        Console.WriteLine(\" - asynchronous operation canceled.\");  \n      }  \n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \n      {  \n        Console.WriteLine(  \n          \" - BabbleTimeout = {0}; InitialSilenceTimeout = {1}\",  \n          e.BabbleTimeout, e.InitialSilenceTimeout);  \n        return;  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(  \n          \" - AudioPosition = {0}; InputStreamEnded = {1}\",  \n          e.AudioPosition, e.InputStreamEnded);  \n      }  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(  \n          \" - Grammar = {0}; Text = {1}; Confidence = {2}\",  \n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\" - No result.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public void RecognizeAsyncCancel ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop
  id: RecognizeAsyncStop
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizeAsyncStop()
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncStop()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Interrompe o reconhecimento assíncrono após a conclusão da operação atual de reconhecimento."
  remarks: "Esse método finaliza reconhecimento assíncrono sem truncamento de entrada. Se a operação assíncrona reconhecimento atual está recebendo a entrada, o reconhecedor continua a aceitar a entrada até que a operação de reconhecimento atual seja concluída. Gera o reconhecedor de <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>ou <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>eventos quando uma operação assíncrona está parada e define o <xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A>propriedade do <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>para `true`.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs> </xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> Esse método para operações assíncronas iniciadas pelo <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>e <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>métodos.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>       Para cancelar imediatamente o reconhecimento assíncrono com apenas a entrada existente, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A>"
  example:
  - "The following example shows part of a console application that demonstrates the use of the RecognizeAsyncStop method. The example creates and loads a speech recognition grammar, initiates a continuing asynchronous recognition operation, and then pauses 2 seconds before it stops the operation. The recognizer receives input from the file, c:\\temp\\audioinput\\sample.wav. Event handlers are included to demonstrate the events that the recognizer raises during the operation.  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace AsynchronousRecognition  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition is complete.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        // Create and load a dictation grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Attach event handlers.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Begin asynchronous recognition from pre-recorded input.  \n        recognizer.SetInputToWaveFile(@\"c:\\temp\\audioinput\\sample.wav\");  \n  \n        completed = false;  \n        Console.WriteLine(\"Begin continuing asynchronous recognition...\");  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Wait 2 seconds and then stop the recognition operation.  \n        Thread.Sleep(TimeSpan.FromSeconds(2));  \n        recognizer.RecognizeAsyncStop();  \n  \n        // Wait for the operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void SpeechDetectedHandler(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechDetectedHandler:\");  \n      Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechHypothesizedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognitionRejectedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognizedHandler.\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\" In RecognizeCompletedHandler.\");  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(  \n          \" - Error occurred during recognition: {0}\", e.Error);  \n        return;  \n      }  \n      if (e.Cancelled)  \n      {  \n        Console.WriteLine(\" - asynchronous operation canceled.\");  \n      }  \n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \n      {  \n        Console.WriteLine(  \n          \" - BabbleTimeout = {0}; InitialSilenceTimeout = {1}\",  \n          e.BabbleTimeout, e.InitialSilenceTimeout);  \n        return;  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(  \n          \" - AudioPosition = {0}; InputStreamEnded = {1}\",  \n          e.AudioPosition, e.InputStreamEnded);  \n      }  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(  \n          \" - Grammar = {0}; Text = {1}; Confidence = {2}\",  \n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\" - No result.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void RecognizeAsyncStop ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted
  id: RecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizeCompleted
  nameWithType: SpeechRecognitionEngine.RecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Gerado quando o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> Finaliza uma operação assíncrona de reconhecimento."
  remarks: "O <xref:System.Speech.Recognition.SpeechRecognitionEngine>do objeto <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>método inicia uma operação assíncrona reconhecimento.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine> Quando o reconhecedor finaliza a operação assíncrona, ela gera esse evento.       Usando o manipulador para o evento RecognizeCompleted, você pode acessar o <xref:System.Speech.Recognition.RecognitionResult>no <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>objeto.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs> </xref:System.Speech.Recognition.RecognitionResult> Se o reconhecimento não foi bem-sucedida, <xref:System.Speech.Recognition.RecognitionResult>será `null`.</xref:System.Speech.Recognition.RecognitionResult> Para determinar se um tempo limite ou uma interrupção de entrada de áudio causado reconhecimento falhar, você pode acessar as propriedades de <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A>, ou <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded%2A>.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded%2A> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A>       Consulte o <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>classe para obter mais informações.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs>       Para obter detalhes sobre os melhores candidatos rejeitado reconhecimento, anexar um manipulador para o <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>evento.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>       Quando você cria um delegado RecognizeCompleted, identifica o método que manipulará o evento. Para associar o evento com o manipulador de eventos, adicione uma instância do representante ao evento. O manipulador de eventos é chamado sempre que o evento ocorre, a menos que você remova o delegado. Para obter mais informações sobre delegados de manipulador de eventos, consulte [eventos e delegados](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example recognizes phrases such as \"Display the list of artists in the jazz category\" or \"Display albums gospel\". The example uses a handler for the RecognizeCompleted event to display information about the results of recognition in the console.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine())  \n      {  \n  \n        //  Create lists of alternative choices.  \n        Choices listTypes = new Choices(new string[] { \"albums\", \"artists\" });  \n        Choices genres = new Choices(new string[] {   \n          \"blues\", \"classical\", \"gospel\", \"jazz\", \"rock\" });  \n  \n        //  Create a GrammarBuilder object and assemble the grammar components.  \n        GrammarBuilder mediaMenu = new GrammarBuilder(\"Display\");  \n        mediaMenu.Append(\"the list of\", 0, 1);  \n        mediaMenu.Append(listTypes);  \n        mediaMenu.Append(\"in the\", 0, 1);  \n        mediaMenu.Append(genres);  \n        mediaMenu.Append(\"category.\", 0, 1);  \n  \n        //  Build a Grammar object from the GrammarBuilder.  \n        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  \n        mediaMenuGrammar.Name = \"Media Chooser\";  \n  \n        // Attach event handlers.  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  \n        recognizer.LoadGrammarCompleted +=   \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(mediaMenuGrammar);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous recognition.  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  \n    {  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(  \n          \"RecognizeCompleted, error occurred during recognition: {0}\", e.Error);  \n        return;  \n      }  \n  \n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \n      {  \n        Console.WriteLine(  \n          \"RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).\",  \n          e.BabbleTimeout, e.InitialSilenceTimeout);  \n        return;  \n      }  \n  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(  \n          \"RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).\",  \n          e.AudioPosition, e.InputStreamEnded);  \n      }  \n  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"RecognizeCompleted:\");  \n        Console.WriteLine(\"  Grammar: \" + e.Result.Grammar.Name);  \n        Console.WriteLine(\"  Recognized text: \" + e.Result.Text);  \n        Console.WriteLine(\"  Confidence score: \" + e.Result.Confidence);  \n        Console.WriteLine(\"  Audio position: \" + e.AudioPosition);  \n      }  \n  \n      else  \n      {  \n        Console.WriteLine(\"RecognizeCompleted: No result.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded:  \" + e.Grammar.Name);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.RecognizeCompletedEventArgs> RecognizeCompleted;
    return:
      type: System.EventHandler{System.Speech.Recognition.RecognizeCompletedEventArgs}
      description: "A ser adicionado."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition
  id: RecognizerAudioPosition
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognitionEngine.RecognizerAudioPosition
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Obtém o local atual do <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> na entrada de áudio que está processando."
  remarks: "A posição de áudio é específica para cada reconhecedor de fala. O valor zero de um fluxo de entrada é estabelecido quando ele está habilitado.       As referências de propriedade RecognizerAudioPosition a <xref:System.Speech.Recognition.SpeechRecognitionEngine>a posição do objeto dentro de sua entrada de áudio.</xref:System.Speech.Recognition.SpeechRecognitionEngine> Por outro lado, o <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A>propriedade faz referência a posição do dispositivo de entrada no seu fluxo de áudio gerado.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> Essas posições podem ser diferentes. Por exemplo, se tiver recebido o reconhecedor de entrada para o qual não tem ainda gerado um resultado de reconhecimento e o valor da propriedade RecognizerAudioPosition é menor que o valor da <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A>propriedade.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A>"
  syntax:
    content: public TimeSpan RecognizerAudioPosition { get; }
    return:
      type: System.TimeSpan
      description: "A posição do reconhecedor de entrada de áudio está processando."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo
  id: RecognizerInfo
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizerInfo
  nameWithType: SpeechRecognitionEngine.RecognizerInfo
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Obtém informações sobre a instância atual do <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>."
  remarks: "Para obter informações sobre todos os identificadores de fala instalados para o sistema atual, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>"
  example:
  - "The following example gets a partial list of data for the current in-process speech recognition engine. For more information, see <xref:System.Speech.Recognition.RecognizerInfo>.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace RecognitionEngine  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer = new SpeechRecognitionEngine())  \n      {  \n        Console.WriteLine(\"Information for the current speech recognition engine:\");  \n        Console.WriteLine(\"  Name: {0}\", recognizer.RecognizerInfo.Name);  \n        Console.WriteLine(\"  Culture: {0}\", recognizer.RecognizerInfo.Culture.ToString());  \n        Console.WriteLine(\"  Description: {0}\", recognizer.RecognizerInfo.Description);  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognizerInfo RecognizerInfo { get; }
    return:
      type: System.Speech.Recognition.RecognizerInfo
      description: "Informações sobre o reconhecedor de fala atual."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached
  id: RecognizerUpdateReached
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizerUpdateReached
  nameWithType: SpeechRecognitionEngine.RecognizerUpdateReached
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Gerado quando um execução <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> pausa para aceitar as modificações."
  remarks: "Os aplicativos devem usar <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>para pausar uma instância em execução de <xref:System.Speech.Recognition.SpeechRecognitionEngine>antes de modificar as configurações ou seus <xref:System.Speech.Recognition.Grammar>objetos.</xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> O <xref:System.Speech.Recognition.SpeechRecognitionEngine>gera esse evento quando ele estiver pronto para aceitar as modificações.</xref:System.Speech.Recognition.SpeechRecognitionEngine>       Por exemplo, o <xref:System.Speech.Recognition.SpeechRecognitionEngine>é pausado, você pode carregar, descarregar, habilitar e desabilitar <xref:System.Speech.Recognition.Grammar>objetos e modificar os valores para o <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, e <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>Propriedades.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> </xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognitionEngine> Para obter mais informações, consulte o <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>       Quando você cria um delegado RecognizerUpdateReached, identifica o método que manipulará o evento. Para associar o evento com o manipulador de eventos, adicione uma instância do representante ao evento. O manipulador de eventos é chamado sempre que o evento ocorre, a menos que você remova o delegado. Para obter mais informações sobre delegados de manipulador de eventos, consulte [eventos e delegados](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example shows a console application that loads and unloads <xref:System.Speech.Recognition.Grammar> objects. The application uses the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> method to request the speech recognition engine to pause so it can receive an update. The application then loads or unloads a <xref:System.Speech.Recognition.Grammar> object.  \n  \n At each update, a handler for RecognizerUpdateReached event writes the name and status of the currently loaded <xref:System.Speech.Recognition.Grammar> objects to the console. As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Collections.Generic;  \nusing System.Threading;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognitionEngine recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognition engine and configure its input.  \n      using (recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Create the first grammar - Farm.  \n        Choices animals = new Choices(new string[] { \"cow\", \"pig\", \"goat\" });  \n        GrammarBuilder farm = new GrammarBuilder(animals);  \n        Grammar farmAnimals = new Grammar(farm);  \n        farmAnimals.Name = \"Farm\";  \n  \n        // Create the second grammar - Fruit.  \n        Choices fruit = new Choices(new string[] { \"apples\", \"peaches\", \"oranges\" });  \n        GrammarBuilder favorite = new GrammarBuilder(fruit);  \n        Grammar favoriteFruit = new Grammar(favorite);  \n        favoriteFruit.Name = \"Fruit\";  \n  \n        // Attach event handlers.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.RecognizerUpdateReached +=  \n          new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  \n  \n        // Load the Farm grammar.  \n        recognizer.LoadGrammar(farmAnimals);  \n  \n        // Start asynchronous, continuous recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n        Console.WriteLine(\"Starting asynchronous, continuous recognition\");  \n        Console.WriteLine(\"  Farm grammar is loaded and enabled.\");  \n  \n        // Pause to recognize farm animals.  \n        Thread.Sleep(7000);  \n        Console.WriteLine();  \n  \n        // Request an update and load the Fruit grammar.  \n        recognizer.RequestRecognizerUpdate();  \n        recognizer.LoadGrammarAsync(favoriteFruit);  \n        Thread.Sleep(7000);  \n  \n        // Request an update and unload the Farm grammar.  \n        recognizer.RequestRecognizerUpdate();  \n        recognizer.UnloadGrammar(farmAnimals);  \n        Thread.Sleep(7000);  \n      }  \n  \n      // Keep the console window open.  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // At the update, get the names and enabled status of the currently loaded grammars.  \n    public static void recognizer_RecognizerUpdateReached(  \n      object sender, RecognizerUpdateReachedEventArgs e)  \n    {  \n      Console.WriteLine();  \n      Console.WriteLine(\"Update reached:\");  \n      Thread.Sleep(1000);  \n  \n      string qualifier;  \n      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  \n      foreach (Grammar g in grammars)  \n      {  \n        qualifier = (g.Enabled) ? \"enabled\" : \"disabled\";  \n        Console.WriteLine(\"  {0} grammar is loaded and {1}.\",  \n        g.Name, qualifier);  \n      }  \n    }  \n  \n    // Write the text of the recognized phrase to the console.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"    Speech recognized: \" + e.Result.Text);  \n    }  \n  \n    // Write a message to the console when recognition fails.  \n    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\"    Recognition attempt failed\");  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs> RecognizerUpdateReached;
    return:
      type: System.EventHandler{System.Speech.Recognition.RecognizerUpdateReachedEventArgs}
      description: "A ser adicionado."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate
  id: RequestRecognizerUpdate
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RequestRecognizerUpdate()
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Solicita que o reconhecedor pausa para atualizar seu estado."
  remarks: "Quando o reconhecedor gera o <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>evento, o <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>propriedade do <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>é `null`.</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>       Para fornecer um token de usuário, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>ou <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> Para especificar um deslocamento de posição de áudio, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>"
  example:
  - "The following example shows a console application that loads and unloads <xref:System.Speech.Recognition.Grammar> objects. The application uses the RequestRecognizerUpdate method to request the speech recognition engine to pause so it can receive an update. The application then loads or unloads a <xref:System.Speech.Recognition.Grammar> object.  \n  \n At each update, a handler for <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> event writes the name and status of the currently loaded <xref:System.Speech.Recognition.Grammar> objects to the console. As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Collections.Generic;  \nusing System.Threading;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognitionEngine recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognition engine and configure its input.  \n      using (recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Create the first grammar - Farm.  \n        Choices animals = new Choices(new string[] { \"cow\", \"pig\", \"goat\" });  \n        GrammarBuilder farm = new GrammarBuilder(animals);  \n        Grammar farmAnimals = new Grammar(farm);  \n        farmAnimals.Name = \"Farm\";  \n  \n        // Create the second grammar - Fruit.  \n        Choices fruit = new Choices(new string[] { \"apples\", \"peaches\", \"oranges\" });  \n        GrammarBuilder favorite = new GrammarBuilder(fruit);  \n        Grammar favoriteFruit = new Grammar(favorite);  \n        favoriteFruit.Name = \"Fruit\";  \n  \n        // Attach event handlers.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.RecognizerUpdateReached +=  \n          new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  \n  \n        // Load the Farm grammar.  \n        recognizer.LoadGrammar(farmAnimals);  \n  \n        // Start asynchronous, continuous recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n        Console.WriteLine(\"Starting asynchronous, continuous recognition\");  \n        Console.WriteLine(\"  Farm grammar is loaded and enabled.\");  \n  \n        // Pause to recognize farm animals.  \n        Thread.Sleep(7000);  \n        Console.WriteLine();  \n  \n        // Request an update and load the Fruit grammar.  \n        recognizer.RequestRecognizerUpdate();  \n        recognizer.LoadGrammarAsync(favoriteFruit);  \n        Thread.Sleep(7000);  \n  \n        // Request an update and unload the Farm grammar.  \n        recognizer.RequestRecognizerUpdate();  \n        recognizer.UnloadGrammar(farmAnimals);  \n        Thread.Sleep(7000);  \n      }  \n  \n      // Keep the console window open.  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // At the update, get the names and enabled status of the currently loaded grammars.  \n    public static void recognizer_RecognizerUpdateReached(  \n      object sender, RecognizerUpdateReachedEventArgs e)  \n    {  \n      Console.WriteLine();  \n      Console.WriteLine(\"Update reached:\");  \n      Thread.Sleep(1000);  \n  \n      string qualifier;  \n      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  \n      foreach (Grammar g in grammars)  \n      {  \n        qualifier = (g.Enabled) ? \"enabled\" : \"disabled\";  \n        Console.WriteLine(\"  {0} grammar is loaded and {1}.\",  \n        g.Name, qualifier);  \n      }  \n    }  \n  \n    // Write the text of the recognized phrase to the console.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"    Speech recognized: \" + e.Result.Text);  \n    }  \n  \n    // Write a message to the console when recognition fails.  \n    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\"    Recognition attempt failed\");  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void RequestRecognizerUpdate ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)
  id: RequestRecognizerUpdate(System.Object)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RequestRecognizerUpdate(Object)
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate(Object)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(Object)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Solicita que o reconhecedor pausa para atualizar seu estado e fornece um token de usuário para o evento associado."
  remarks: "Quando o reconhecedor gera o <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>evento, o <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>propriedade do <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>contém o valor da `userToken` parâmetro.</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>       Para especificar um deslocamento de posição de áudio, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>"
  syntax:
    content: public void RequestRecognizerUpdate (object userToken);
    parameters:
    - id: userToken
      type: System.Object
      description: "Informações definidas pelo usuário que contém informações para a operação."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  id: RequestRecognizerUpdate(System.Object,System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RequestRecognizerUpdate(Object,TimeSpan)
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate(Object,TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(Object,TimeSpan)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Solicita que o reconhecedor pausa para atualizar seu estado e fornece um deslocamento e um token de usuário para o evento associado."
  remarks: "O reconhecedor não iniciará a solicitação de atualização do reconhecedor até que o reconhecedor <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>é igual a atual <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A>mais `audioPositionAheadToRaiseUpdate`.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>       Quando o reconhecedor gera o <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>evento, o <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>propriedade do <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>contém o valor da `userToken` parâmetro.</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>"
  syntax:
    content: public void RequestRecognizerUpdate (object userToken, TimeSpan audioPositionAheadToRaiseUpdate);
    parameters:
    - id: userToken
      type: System.Object
      description: "Informações definidas pelo usuário que contém informações para a operação."
    - id: audioPositionAheadToRaiseUpdate
      type: System.TimeSpan
      description: "O deslocamento do atual <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*>para atrasar a solicitação.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*>"
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)
  id: SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
  nameWithType: SpeechRecognitionEngine.SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Configura o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> objeto para receber entrada de um fluxo de áudio."
  remarks: "Se o reconhecedor atinge o final do fluxo de entrada durante uma operação de reconhecimento, a operação de reconhecimento finaliza com a entrada disponível. Todas as operações subsequentes de reconhecimento podem gerar uma exceção, a menos que você atualizar a entrada para o reconhecedor."
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example uses input from an audio file, example.wav, that contains the phrases, \"testing testing one two three\" and \"mister cooper\", separated by a pause. The example generates the following output.  \n  \n```  \n  \nStarting asynchronous recognition...  \n  Recognized text =  Testing testing 123  \n  Recognized text =  Mr. Cooper  \n  End of stream encountered.  \nDone.  \n  \nPress any key to exit...  \n```  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.IO;  \nusing System.Speech.AudioFormat;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace InputExamples  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition is complete.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Configure the input to the recognizer.  \n        recognizer.SetInputToAudioStream(  \n          File.OpenRead(@\"c:\\temp\\audioinput\\example.wav\"),  \n          new SpeechAudioFormatInfo(  \n            44100, AudioBitsPerSample.Sixteen, AudioChannel.Mono));  \n  \n        // Attach event handlers.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Perform recognition of the whole file.  \n        Console.WriteLine(\"Starting asynchronous recognition...\");  \n        completed = false;  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null && e.Result.Text != null)  \n      {  \n        Console.WriteLine(\"  Recognized text =  {0}\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  Recognized text not available.\");  \n      }  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"  Error encountered, {0}: {1}\",  \n          e.Error.GetType().Name, e.Error.Message);  \n      }  \n      if (e.Cancelled)  \n      {  \n        Console.WriteLine(\"  Operation cancelled.\");  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(\"  End of stream encountered.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void SetInputToAudioStream (System.IO.Stream audioSource, System.Speech.AudioFormat.SpeechAudioFormatInfo audioFormat);
    parameters:
    - id: audioSource
      type: System.IO.Stream
      description: "O fluxo de entrada de áudio."
    - id: audioFormat
      type: System.Speech.AudioFormat.SpeechAudioFormatInfo
      description: "O formato de entrada de áudio."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice
  id: SetInputToDefaultAudioDevice
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SetInputToDefaultAudioDevice()
  nameWithType: SpeechRecognitionEngine.SetInputToDefaultAudioDevice()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Configura o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> objeto para receber entrada do dispositivo de áudio padrão."
  remarks: ''
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example uses output from the default audio device, performs multiple, asynchronous recognition operations, and exits when a user utters the phrase, \"exit\".  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace DefaultInput  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition has finished.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load the exit grammar.  \n        Grammar exitGrammar = new Grammar(new GrammarBuilder(\"exit\"));  \n        exitGrammar.Name = \"Exit Grammar\";  \n        recognizer.LoadGrammar(exitGrammar);  \n  \n        // Create and load the dictation grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Attach event handlers to the recognizer.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Assign input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Begin asynchronous recognition.  \n        Console.WriteLine(\"Starting recognition...\");  \n        completed = false;  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Wait for recognition to finish.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"  Speech recognized:\");  \n      string grammarName = \"<not available>\";  \n      if (e.Result.Grammar.Name != null &&  \n        !e.Result.Grammar.Name.Equals(string.Empty))  \n      {  \n        grammarName = e.Result.Grammar.Name;  \n      }  \n      Console.WriteLine(\"    {0,-17} - {1}\",  \n        grammarName, e.Result.Text);  \n  \n      if (grammarName.Equals(\"Exit Grammar\"))  \n      {  \n        ((SpeechRecognitionEngine)sender).RecognizeAsyncCancel();  \n      }  \n    }  \n  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"  Recognition completed.\");  \n      completed = true;  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public void SetInputToDefaultAudioDevice ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull
  id: SetInputToNull
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SetInputToNull()
  nameWithType: SpeechRecognitionEngine.SetInputToNull()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Desativa a entrada para o reconhecedor de fala."
  remarks: "Configurar o <xref:System.Speech.Recognition.SpeechRecognitionEngine>objeto para nenhuma entrada ao usar o <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>e <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>métodos, ou quando um mecanismo de reconhecimento temporariamente off-line.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine>"
  syntax:
    content: public void SetInputToNull ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)
  id: SetInputToWaveFile(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SetInputToWaveFile(String)
  nameWithType: SpeechRecognitionEngine.SetInputToWaveFile(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Configura o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> objeto para receber entrada de um arquivo de formato de áudio (. wav) de forma de onda."
  remarks: "Se o reconhecedor atinge o final do arquivo de entrada durante uma operação de reconhecimento, a operação de reconhecimento finaliza com a entrada disponível. Todas as operações subsequentes de reconhecimento podem gerar uma exceção, a menos que você atualizar a entrada para o reconhecedor."
  example:
  - "The following example performs recognition on the audio in a .wav file and writes the recognized text to the console.  \n  \n```  \nusing System;  \nusing System.IO;  \nusing System.Speech.Recognition;  \nusing System.Speech.AudioFormat;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine())  \n      {  \n  \n        // Create and load a grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Configure the input to the recognizer.  \nrecognizer.SetInputToWaveFile(@\"c:\\temp\\SampleWAVInput.wav\");  \n  \n        // Attach event handlers for the results of recognition.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.RecognizeCompleted +=   \n          new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  \n  \n        // Perform recognition on the entire file.  \n        Console.WriteLine(\"Starting asynchronous recognition...\");  \n        completed = false;  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        while (!completed)  \n        {  \n          Console.ReadLine();  \n        }  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null && e.Result.Text != null)  \n      {  \n        Console.WriteLine(\"  Recognized text =  {0}\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  Recognized text not available.\");  \n      }  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  \n    {  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"  Error encountered, {0}: {1}\",  \n        e.Error.GetType().Name, e.Error.Message);  \n      }  \n      if (e.Cancelled)  \n      {  \n        Console.WriteLine(\"  Operation cancelled.\");  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(\"  End of stream encountered.\");  \n      }  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void SetInputToWaveFile (string path);
    parameters:
    - id: path
      type: System.String
      description: "O caminho do arquivo a ser usado como entrada."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)
  id: SetInputToWaveStream(System.IO.Stream)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SetInputToWaveStream(Stream)
  nameWithType: SpeechRecognitionEngine.SetInputToWaveStream(Stream)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(Stream)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Configura o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> objeto para receber entrada de um fluxo que contém dados de formato de áudio (. wav) de forma de onda."
  remarks: "Se o reconhecedor atinge o final do fluxo de entrada durante uma operação de reconhecimento, a operação de reconhecimento finaliza com a entrada disponível. Todas as operações subsequentes de reconhecimento podem gerar uma exceção, a menos que você atualizar a entrada para o reconhecedor."
  syntax:
    content: public void SetInputToWaveStream (System.IO.Stream audioSource);
    parameters:
    - id: audioSource
      type: System.IO.Stream
      description: "O fluxo que contém os dados de áudio."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected
  id: SpeechDetected
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechDetected
  nameWithType: SpeechRecognitionEngine.SpeechDetected
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Gerado quando o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> detecta a entrada, ele pode identificar como fala."
  remarks: "Cada reconhecedor de fala tem um algoritmo para distinguir entre silêncio e fala. Quando o <xref:System.Speech.Recognition.SpeechRecognitionEngine>executa uma operação de reconhecimento de fala, ele gera o evento de SpeechDetected quando o algoritmo identifica a entrada como fala.</xref:System.Speech.Recognition.SpeechRecognitionEngine> O <xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A>propriedade associado <xref:System.Speech.Recognition.SpeechDetectedEventArgs>objeto indica o local no fluxo de entrada em que o reconhecedor detectado fala.</xref:System.Speech.Recognition.SpeechDetectedEventArgs> </xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A> O <xref:System.Speech.Recognition.SpeechRecognitionEngine>gera o evento SpeechDetected antes de gerar qualquer uma da <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>, ou <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>eventos.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine>       Para obter mais informações, consulte o <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>, e <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>métodos.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>       Quando você cria um delegado SpeechDetected, identifica o método que manipulará o evento. Para associar o evento com o manipulador de eventos, adicione uma instância do representante ao evento. O manipulador de eventos é chamado sempre que o evento ocorre, a menos que você remova o delegado. Para obter mais informações sobre delegados de manipulador de eventos, consulte [eventos e delegados](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example is part of a console application for choosing origin and destination cities for a flight. The application recognizes phrases such as \"I want to fly from Miami to Chicago.\"  The example uses the SpeechDetected event to report the <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> each time speech is detected.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine())  \n      {  \n  \n        // Create a grammar.  \n        Choices cities = new Choices(new string[] {   \n          \"Los Angeles\", \"New York\", \"Chicago\", \"San Francisco\", \"Miami\", \"Dallas\" });  \n  \n        GrammarBuilder gb = new GrammarBuilder();  \n        gb.Append(\"I would like to fly from\");  \n        gb.Append(cities);  \n        gb.Append(\"to\");  \n        gb.Append(cities);  \n  \n        // Create a Grammar object and load it to the recognizer.  \n        Grammar g = new Grammar(gb);  \n        g.Name = (\"City Chooser\");  \n        recognizer.LoadGrammarAsync(g);  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start recognition.  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\"  Speech detected at AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"  Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs> SpeechDetected;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechDetectedEventArgs}
      description: "A ser adicionado."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized
  id: SpeechHypothesized
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechHypothesized
  nameWithType: SpeechRecognitionEngine.SpeechHypothesized
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Gerado quando o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> reconheceu uma palavra ou palavras que podem ser um componente de várias frases completas em uma gramática."
  remarks: "O <xref:System.Speech.Recognition.SpeechRecognitionEngine>gera vários eventos SpeechHypothesized conforme ele tenta identificar uma frase de entrada.</xref:System.Speech.Recognition.SpeechRecognitionEngine> Você pode acessar o texto de frases parcialmente reconhecidos no <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>propriedade o <xref:System.Speech.Recognition.SpeechHypothesizedEventArgs>objeto no manipulador para o evento SpeechHypothesized.</xref:System.Speech.Recognition.SpeechHypothesizedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> Normalmente, manipular esses eventos só é útil para depuração.       <xref:System.Speech.Recognition.SpeechHypothesizedEventArgs>derivado de <xref:System.Speech.Recognition.RecognitionEventArgs>.</xref:System.Speech.Recognition.RecognitionEventArgs></xref:System.Speech.Recognition.SpeechHypothesizedEventArgs>       Para obter mais informações, consulte o <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>propriedade e o <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>, e <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>métodos.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>       Quando você cria um delegado SpeechHypothesized, identifica o método que manipulará o evento. Para associar o evento com o manipulador de eventos, adicione uma instância do representante ao evento. O manipulador de eventos é chamado sempre que o evento ocorre, a menos que você remova o delegado. Para obter mais informações sobre delegados de manipulador de eventos, consulte [eventos e delegados](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example recognizes phrases such as \"Display the list of artists in the jazz category\". The example uses the SpeechHypothesized event to display incomplete phrase fragments in the console as they are recognized.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine())  \n      {  \n  \n        // Create a grammar.  \n        //  Create lists of alternative choices.  \n        Choices listTypes = new Choices(new string[] { \"albums\", \"artists\" });  \n        Choices genres = new Choices(new string[] {   \n          \"blues\", \"classical\", \"gospel\", \"jazz\", \"rock\" });  \n  \n        //  Create a GrammarBuilder object and assemble the grammar components.  \n        GrammarBuilder mediaMenu = new GrammarBuilder(\"Display the list of\");  \n        mediaMenu.Append(listTypes);  \n        mediaMenu.Append(\"in the\");  \n        mediaMenu.Append(genres);  \n        mediaMenu.Append(\"category.\");  \n  \n        //  Build a Grammar object from the GrammarBuilder.  \n        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  \n        mediaMenuGrammar.Name = \"Media Chooser\";  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(recognizer_SpeechHypothesized);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(mediaMenuGrammar);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous recognition.  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void recognizer_SpeechHypothesized(object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech hypothesized: \" + e.Result.Text);  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n      Console.WriteLine();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine();   \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs> SpeechHypothesized;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechHypothesizedEventArgs}
      description: "A ser adicionado."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected
  id: SpeechRecognitionRejected
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognitionRejected
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionRejected
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Gerado quando o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> recebe entrada que não corresponde a nenhum dos carregados e habilitados <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> objetos."
  remarks: "O reconhecedor gera esse evento se determinar que entrada não coincide com confiança suficiente qualquer um dos seus carregados e habilitados <xref:System.Speech.Recognition.Grammar>objetos.</xref:System.Speech.Recognition.Grammar> O <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>propriedade o <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>contém o rejeitado <xref:System.Speech.Recognition.RecognitionResult>objeto.</xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> Você pode usar o manipulador para o evento SpeechRecognitionRejected para recuperar o reconhecimento <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>que foram rejeitadas e seus <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>pontuações.</xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> </xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>       Se seu aplicativo estiver usando um <xref:System.Speech.Recognition.SpeechRecognitionEngine>instância, você pode modificar o nível de confiança no qual fala entrada é aceita ou rejeitada com um do <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>métodos.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine> Você pode modificar como o reconhecimento de fala responde a não fala de entrada usando o <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>, e <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>Propriedades.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>       Quando você cria um delegado SpeechRecognitionRejected, identifica o método que manipulará o evento. Para associar o evento com o manipulador de eventos, adicione uma instância do representante ao evento. O manipulador de eventos é chamado sempre que o evento ocorre, a menos que você remova o delegado. Para obter mais informações sobre delegados de manipulador de eventos, consulte [eventos e delegados](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example recognizes phrases such as \"Display the list of artists in the jazz category\" or \"Display albums gospel\". The example uses a handler for the SpeechRecognitionRejected event to display a notification in the console when the speech input cannot be matched to the contents of the grammar with sufficient <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> to produce a successful recognition. The handler also displays recognition result <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> that were rejected because of low confidence scores.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create a grammar.  \n        //  Create lists of alternative choices.  \n        Choices listTypes = new Choices(new string[] { \"albums\", \"artists\" });  \n        Choices genres = new Choices(new string[] {   \n          \"blues\", \"classical\", \"gospel\", \"jazz\", \"rock\" });  \n  \n        //  Create a GrammarBuilder object and assemble the grammar components.  \n        GrammarBuilder mediaMenu = new GrammarBuilder(\"Display\");  \n        mediaMenu.Append(\"the list of\", 0, 1);  \n        mediaMenu.Append(listTypes);  \n        mediaMenu.Append(\"in the\", 0, 1);  \n        mediaMenu.Append(genres);  \n        mediaMenu.Append(\"category\", 0, 1);  \n  \n        //  Build a Grammar object from the GrammarBuilder.  \n        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  \n        mediaMenuGrammar.Name = \"Media Chooser\";  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(mediaMenuGrammar);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech input was rejected.\");  \n      foreach (RecognizedPhrase phrase in e.Result.Alternates)  \n      {  \n      Console.WriteLine(\"  Rejected phrase: \" + phrase.Text);  \n      Console.WriteLine(\"  Confidence score: \" + phrase.Confidence);  \n      }  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n      Console.WriteLine(\"  Confidence score: \" + e.Result.Confidence);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> SpeechRecognitionRejected;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechRecognitionRejectedEventArgs}
      description: "A ser adicionado."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized
  id: SpeechRecognized
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognized
  nameWithType: SpeechRecognitionEngine.SpeechRecognized
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Gerado quando o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> recebe entrada que corresponde a qualquer um de seus carregados e habilitados <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> objetos."
  remarks: "Você pode iniciar uma operação de reconhecimento usando um da <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>ou <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>métodos.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> O reconhecedor gera o evento de SpeechRecognized se determinar que entrada corresponde a um dos seus carregado <xref:System.Speech.Recognition.Grammar>objetos com um nível suficiente de confiança para constituir reconhecimento.</xref:System.Speech.Recognition.Grammar> O <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>propriedade o <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>contém o aceito <xref:System.Speech.Recognition.RecognitionResult>objeto.</xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> Manipuladores de eventos de SpeechRecognized podem obter a frase reconhecida como uma lista de reconhecimento <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>com pontuações de confiança inferiores.</xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>       Se seu aplicativo estiver usando um <xref:System.Speech.Recognition.SpeechRecognitionEngine>instância, você pode modificar o nível de confiança no qual fala entrada é aceita ou rejeitada com um do <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>métodos.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine>  Você pode modificar como o reconhecimento de fala responde a não fala de entrada usando o <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>, e <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>Propriedades.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>       Quando o reconhecedor recebe entrada que corresponde a uma gramática, o <xref:System.Speech.Recognition.Grammar>objeto pode gerar seu <xref:System.Speech.Recognition.Grammar.SpeechRecognized>evento.</xref:System.Speech.Recognition.Grammar.SpeechRecognized> </xref:System.Speech.Recognition.Grammar> O <xref:System.Speech.Recognition.Grammar>do objeto <xref:System.Speech.Recognition.Grammar.SpeechRecognized>é gerado antes do evento SpeechRecognized do reconhecedor de fala.</xref:System.Speech.Recognition.Grammar.SpeechRecognized> </xref:System.Speech.Recognition.Grammar> As tarefas específicas a uma gramática específica sempre devem ser realizadas por um manipulador para o <xref:System.Speech.Recognition.Grammar.SpeechRecognized>evento.</xref:System.Speech.Recognition.Grammar.SpeechRecognized>       Quando você cria um delegado SpeechRecognized, identifica o método que manipulará o evento. Para associar o evento com o manipulador de eventos, adicione uma instância do representante ao evento. O manipulador de eventos é chamado sempre que o evento ocorre, a menos que você remova o delegado. Para obter mais informações sobre delegados de manipulador de eventos, consulte [eventos e delegados](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example is part of a console application that creates speech recognition grammar, constructs a <xref:System.Speech.Recognition.Grammar> object, and loads it into the <xref:System.Speech.Recognition.SpeechRecognitionEngine> to perform recognition. The example demonstrates speech input to a <xref:System.Speech.Recognition.SpeechRecognitionEngine>, the associated recognition results, and the associated events raised by the speech recognizer.  \n  \n Spoken input such as \"I want to fly from Chicago to Miami\" will trigger a SpeechRecognized event. Speaking the phrase \"Fly me from Houston to Chicago \" will not trigger a SpeechRecognized event.  \n  \n The example uses a handler for the SpeechRecognized event to display successfully recognized phrases and the semantics they contain in the console.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer = new SpeechRecognitionEngine())  \n      {  \n  \n        // Create SemanticResultValue objects that contain cities and airport codes.  \n        SemanticResultValue chicago = new SemanticResultValue(\"Chicago\", \"ORD\");  \n        SemanticResultValue boston = new SemanticResultValue(\"Boston\", \"BOS\");  \n        SemanticResultValue miami = new SemanticResultValue(\"Miami\", \"MIA\");  \n        SemanticResultValue dallas = new SemanticResultValue(\"Dallas\", \"DFW\");  \n  \n        // Create a Choices object and add the SemanticResultValue objects, using  \n        // implicit conversion from SemanticResultValue to GrammarBuilder  \n        Choices cities = new Choices();  \n        cities.Add(new Choices(new GrammarBuilder[] { chicago, boston, miami, dallas }));  \n  \n        // Build the phrase and add SemanticResultKeys.  \n        GrammarBuilder chooseCities = new GrammarBuilder();  \n        chooseCities.Append(\"I want to fly from\");  \n        chooseCities.Append(new SemanticResultKey(\"origin\", cities));  \n        chooseCities.Append(\"to\");  \n        chooseCities.Append(new SemanticResultKey(\"destination\", cities));  \n  \n        // Build a Grammar object from the GrammarBuilder.  \n        Grammar bookFlight = new Grammar(chooseCities);  \n        bookFlight.Name = \"Book Flight\";  \n  \n        // Add a handler for the LoadGrammarCompleted event.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n        // Add a handler for the SpeechRecognized event.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(bookFlight);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start recognition.  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n      Console.WriteLine();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized:  \" + e.Result.Text);  \n      Console.WriteLine();  \n      Console.WriteLine(\"Semantic results:\");  \n      Console.WriteLine(\"  The flight origin is \" + e.Result.Semantics[\"origin\"].Value);  \n      Console.WriteLine(\"  The flight destination is \" + e.Result.Semantics[\"destination\"].Value);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs> SpeechRecognized;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechRecognizedEventArgs}
      description: "A ser adicionado."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars
  id: UnloadAllGrammars
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: UnloadAllGrammars()
  nameWithType: SpeechRecognitionEngine.UnloadAllGrammars()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Descarrega todos <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> objetos a partir do reconhecedor."
  remarks: "Se o reconhecedor está carregando no momento um <xref:System.Speech.Recognition.Grammar>de forma assíncrona, este método espera até que o <xref:System.Speech.Recognition.Grammar>é carregado, antes de ele descarrega todos o <xref:System.Speech.Recognition.Grammar>objetos do <xref:System.Speech.Recognition.SpeechRecognitionEngine>instância.</xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.Grammar>       Para descarregar uma gramática específica, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A>"
  example:
  - "The following example shows part of a console application that demonstrates the synchronous loading and unloading of speech recognition grammars.  \n  \n```  \nLoading grammars...  \nLoaded grammars:  \n - Grammar1  \n - Grammar2  \n - Grammar3  \n  \nUnloading Grammar1...  \nLoaded grammars:  \n - Grammar2  \n - Grammar3  \n  \nUnloading all grammars...  \nNo grammars loaded.  \n  \nPress any key to exit...  \n```  \n  \n```c#  \n  \nusing System;  \nusing System.Collections.Generic;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \n  \nnamespace UnloadGrammars  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        Console.WriteLine(\"Loading grammars...\");  \n  \n        // Create and load a number of grammars.  \n        Grammar grammar1 = new Grammar(new GrammarBuilder(\"first grammar\"));  \n        grammar1.Name = \"Grammar1\";  \n        recognizer.LoadGrammar(grammar1);  \n  \n        Grammar grammar2 = new Grammar(new GrammarBuilder(\"second grammar\"));  \n        grammar2.Name = \"Grammar2\";  \n        recognizer.LoadGrammar(grammar2);  \n  \n        Grammar grammar3 = new Grammar(new GrammarBuilder(\"third grammar\"));  \n        grammar3.Name = \"Grammar3\";  \n        recognizer.LoadGrammar(grammar3);  \n  \n        // List the recognizer's loaded grammars.  \n        ListGrammars(recognizer);  \n  \n        // Unload one grammar and list the loaded grammars.  \n        Console.WriteLine(\"Unloading Grammar1...\");  \n        recognizer.UnloadGrammar(grammar1);  \n        ListGrammars(recognizer);  \n  \n        // Unload all grammars and list the loaded grammars.  \n        Console.WriteLine(\"Unloading all grammars...\");  \n        recognizer.UnloadAllGrammars();  \n        ListGrammars(recognizer);  \n      }  \n  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    private static void ListGrammars(SpeechRecognitionEngine recognizer)  \n    {  \n      // Make a copy of the recognizer's grammar collection.  \n      List<Grammar> loadedGrammars = new List<Grammar>(recognizer.Grammars);  \n  \n      if (loadedGrammars.Count > 0)  \n      {  \n        Console.WriteLine(\"Loaded grammars:\");  \n        foreach (Grammar g in recognizer.Grammars)  \n        {  \n          Console.WriteLine(\" - {0}\", g.Name);  \n        }  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No grammars loaded.\");  \n      }  \n      Console.WriteLine();  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public void UnloadAllGrammars ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)
  id: UnloadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: UnloadGrammar(Grammar)
  nameWithType: SpeechRecognitionEngine.UnloadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Descarrega um especificado <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> de objeto o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> instância."
  remarks: "Se o reconhecedor está em execução, os aplicativos devem usar <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>para pausar o <xref:System.Speech.Recognition.SpeechRecognitionEngine>instância antes de carregamento, descarregamento, habilitar ou desabilitar um <xref:System.Speech.Recognition.Grammar>objeto.</xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> Para descarregar todos os <xref:System.Speech.Recognition.Grammar>objetos, use o <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A>método.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A> </xref:System.Speech.Recognition.Grammar>"
  example:
  - "The following example shows part of a console application that demonstrates the synchronous loading and unloading of speech recognition grammars.  \n  \n```  \nLoading grammars...  \nLoaded grammars:  \n - Grammar1  \n - Grammar2  \n - Grammar3  \n  \nUnloading Grammar1...  \nLoaded grammars:  \n - Grammar2  \n - Grammar3  \n  \nUnloading all grammars...  \nNo grammars loaded.  \n  \nPress any key to exit...  \n```  \n  \n```c#  \n  \nusing System;  \nusing System.Collections.Generic;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \n  \nnamespace UnloadGrammars  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        Console.WriteLine(\"Loading grammars...\");  \n  \n        // Create and load a number of grammars.  \n        Grammar grammar1 = new Grammar(new GrammarBuilder(\"first grammar\"));  \n        grammar1.Name = \"Grammar1\";  \n        recognizer.LoadGrammar(grammar1);  \n  \n        Grammar grammar2 = new Grammar(new GrammarBuilder(\"second grammar\"));  \n        grammar2.Name = \"Grammar2\";  \n        recognizer.LoadGrammar(grammar2);  \n  \n        Grammar grammar3 = new Grammar(new GrammarBuilder(\"third grammar\"));  \n        grammar3.Name = \"Grammar3\";  \n        recognizer.LoadGrammar(grammar3);  \n  \n        // List the recognizer's loaded grammars.  \n        ListGrammars(recognizer);  \n  \n        // Unload one grammar and list the loaded grammars.  \n        Console.WriteLine(\"Unloading Grammar1...\");  \n        recognizer.UnloadGrammar(grammar1);  \n        ListGrammars(recognizer);  \n  \n        // Unload all grammars and list the loaded grammars.  \n        Console.WriteLine(\"Unloading all grammars...\");  \n        recognizer.UnloadAllGrammars();  \n        ListGrammars(recognizer);  \n      }  \n  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    private static void ListGrammars(SpeechRecognitionEngine recognizer)  \n    {  \n      // Make a copy of the recognizer's grammar collection.  \n      List<Grammar> loadedGrammars = new List<Grammar>(recognizer.Grammars);  \n  \n      if (loadedGrammars.Count > 0)  \n      {  \n        Console.WriteLine(\"Loaded grammars:\");  \n        foreach (Grammar g in recognizer.Grammars)  \n        {  \n          Console.WriteLine(\" - {0}\", g.Name);  \n        }  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No grammars loaded.\");  \n      }  \n      Console.WriteLine();  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public void UnloadGrammar (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "O objeto de gramática descarregar."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>Grammar</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "A gramática não está carregada neste reconhecedor ou neste reconhecedor atualmente está carregando a gramática de forma assíncrona."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)
  id: UpdateRecognizerSetting(System.String,System.Int32)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: UpdateRecognizerSetting(String,Int32)
  nameWithType: SpeechRecognitionEngine.UpdateRecognizerSetting(String,Int32)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(String,Int32)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Atualiza a configuração especificada para o <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> com o valor inteiro especificado."
  remarks: "Com exceção de `PersistedBackgroundAdaptation`, valores de propriedade definidos usando o método UpdateRecognizerSetting permanecem em vigor apenas para a instância atual do <xref:System.Speech.Recognition.SpeechRecognitionEngine>, após o qual reverter as configurações padrão.</xref:System.Speech.Recognition.SpeechRecognitionEngine> Consulte <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>para obter descrições de configurações com suporte.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>"
  example:
  - "The following example is part of a console application that outputs the values for a number of the settings defined for the recognizer that supports the en-US locale. The example updates the confidence level settings, and then queries the recognizer to check the updated values. The example generates the following output.  \n  \n```  \nSettings for recognizer MS-1033-80-DESK:  \n  \n  ResourceUsage                  is not supported by this recognizer.  \n  ResponseSpeed                  = 150  \n  ComplexResponseSpeed           = 500  \n  AdaptationOn                   = 1  \n  PersistedBackgroundAdaptation  = 1  \n  \nUpdated settings:  \n  \n  ResourceUsage                  is not supported by this recognizer.  \n  ResponseSpeed                  = 200  \n  ComplexResponseSpeed           = 300  \n  AdaptationOn                   = 0  \n  PersistedBackgroundAdaptation  = 0  \n  \nPress any key to exit...  \n```  \n  \n```c#  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \n  \nnamespace RecognizerSettings  \n{  \n  class Program  \n  {  \n    static readonly string[] settings = new string[] {  \n      \"ResourceUsage\",  \n      \"ResponseSpeed\",  \n      \"ComplexResponseSpeed\",  \n      \"AdaptationOn\",  \n      \"PersistedBackgroundAdaptation\",  \n    };  \n  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        Console.WriteLine(\"Settings for recognizer {0}:\",  \n          recognizer.RecognizerInfo.Name);  \n        Console.WriteLine();  \n  \n        // List the current settings.  \n        ListSettings(recognizer);  \n  \n        // Change some of the settings.  \n        recognizer.UpdateRecognizerSetting(\"ResponseSpeed\", 200);  \n        recognizer.UpdateRecognizerSetting(\"ComplexResponseSpeed\", 300);  \n        recognizer.UpdateRecognizerSetting(\"AdaptationOn\", 1);  \n        recognizer.UpdateRecognizerSetting(\"PersistedBackgroundAdaptation\", 0);  \n  \n        Console.WriteLine(\"Updated settings:\");  \n        Console.WriteLine();  \n  \n        // List the updated settings.  \n        ListSettings(recognizer);  \n      }  \n  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    private static void ListSettings(SpeechRecognitionEngine recognizer)  \n    {  \n      foreach (string setting in settings)  \n      {  \n        try  \n        {  \n          object value = recognizer.QueryRecognizerSetting(setting);  \n          Console.WriteLine(\"  {0,-30} = {1}\", setting, value);  \n        }  \n        catch  \n        {  \n          Console.WriteLine(\"  {0,-30} is not supported by this recognizer.\",  \n            setting);  \n        }  \n      }  \n      Console.WriteLine();  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void UpdateRecognizerSetting (string settingName, int updatedValue);
    parameters:
    - id: settingName
      type: System.String
      description: "O nome da configuração para atualizar."
    - id: updatedValue
      type: System.Int32
      description: "O novo valor para a configuração."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>settingName</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>settingName</code>é a cadeia de caracteres vazia (&quot;&quot;)."
  - type: System.Collections.Generic.KeyNotFoundException
    commentId: T:System.Collections.Generic.KeyNotFoundException
    description: "O reconhecedor não tem uma configuração com esse nome."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)
  id: UpdateRecognizerSetting(System.String,System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: UpdateRecognizerSetting(String,String)
  nameWithType: SpeechRecognitionEngine.UpdateRecognizerSetting(String,String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(String,String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Atualiza a configuração de mecanismo de reconhecimento de fala especificado com o valor de cadeia de caracteres especificada."
  remarks: "Com exceção de `PersistedBackgroundAdaptation`, valores de propriedade definidos usando o método UpdateRecognizerSetting permanecem em vigor apenas para a instância atual do <xref:System.Speech.Recognition.SpeechRecognitionEngine>, após o qual reverter as configurações padrão.</xref:System.Speech.Recognition.SpeechRecognitionEngine> Consulte <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>para obter descrições de configurações com suporte.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>"
  syntax:
    content: public void UpdateRecognizerSetting (string settingName, string updatedValue);
    parameters:
    - id: settingName
      type: System.String
      description: "O nome da configuração para atualizar."
    - id: updatedValue
      type: System.String
      description: "O novo valor para a configuração."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>settingName</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>settingName</code>é a cadeia de caracteres vazia (&quot;&quot;)."
  - type: System.Collections.Generic.KeyNotFoundException
    commentId: T:System.Collections.Generic.KeyNotFoundException
    description: "O reconhecedor não tem uma configuração com esse nome."
  platform:
  - net462
references:
- uid: System.Object
  isExternal: false
  name: System.Object
- uid: System.ArgumentException
  isExternal: true
  name: System.ArgumentException
- uid: System.ArgumentNullException
  isExternal: true
  name: System.ArgumentNullException
- uid: System.ArgumentOutOfRangeException
  isExternal: true
  name: System.ArgumentOutOfRangeException
- uid: System.InvalidOperationException
  isExternal: true
  name: System.InvalidOperationException
- uid: System.NotSupportedException
  isExternal: true
  name: System.NotSupportedException
- uid: System.OperationCanceledException
  isExternal: true
  name: System.OperationCanceledException
- uid: System.Collections.Generic.KeyNotFoundException
  isExternal: true
  name: System.Collections.Generic.KeyNotFoundException
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionEngine()
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionEngine(CultureInfo)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(CultureInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(CultureInfo)
- uid: System.Globalization.CultureInfo
  parent: System.Globalization
  isExternal: true
  name: CultureInfo
  nameWithType: CultureInfo
  fullName: System.Globalization.CultureInfo
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionEngine(RecognizerInfo)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(RecognizerInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(RecognizerInfo)
- uid: System.Speech.Recognition.RecognizerInfo
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizerInfo
  nameWithType: RecognizerInfo
  fullName: System.Speech.Recognition.RecognizerInfo
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionEngine(String)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(String)
- uid: System.String
  parent: System
  isExternal: true
  name: String
  nameWithType: String
  fullName: System.String
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioFormat
  nameWithType: SpeechRecognitionEngine.AudioFormat
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat
- uid: System.Speech.AudioFormat.SpeechAudioFormatInfo
  parent: System.Speech.AudioFormat
  isExternal: false
  name: SpeechAudioFormatInfo
  nameWithType: SpeechAudioFormatInfo
  fullName: System.Speech.AudioFormat.SpeechAudioFormatInfo
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioLevel
  nameWithType: SpeechRecognitionEngine.AudioLevel
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel
- uid: System.Int32
  parent: System
  isExternal: true
  name: Int32
  nameWithType: Int32
  fullName: System.Int32
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioLevelUpdated
  nameWithType: SpeechRecognitionEngine.AudioLevelUpdated
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated
- uid: System.EventHandler{System.Speech.Recognition.AudioLevelUpdatedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioLevelUpdatedEventArgs>
  nameWithType: EventHandler<AudioLevelUpdatedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioLevelUpdatedEventArgs
    name: AudioLevelUpdatedEventArgs
    nameWithType: AudioLevelUpdatedEventArgs
    fullName: AudioLevelUpdatedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioPosition
  nameWithType: SpeechRecognitionEngine.AudioPosition
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition
- uid: System.TimeSpan
  parent: System
  isExternal: true
  name: TimeSpan
  nameWithType: TimeSpan
  fullName: System.TimeSpan
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioSignalProblemOccurred
  nameWithType: SpeechRecognitionEngine.AudioSignalProblemOccurred
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred
- uid: System.EventHandler{System.Speech.Recognition.AudioSignalProblemOccurredEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioSignalProblemOccurredEventArgs>
  nameWithType: EventHandler<AudioSignalProblemOccurredEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioSignalProblemOccurredEventArgs
    name: AudioSignalProblemOccurredEventArgs
    nameWithType: AudioSignalProblemOccurredEventArgs
    fullName: AudioSignalProblemOccurredEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioState
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioState
  nameWithType: SpeechRecognitionEngine.AudioState
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioState
- uid: System.Speech.Recognition.AudioState
  parent: System.Speech.Recognition
  isExternal: false
  name: AudioState
  nameWithType: AudioState
  fullName: System.Speech.Recognition.AudioState
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioStateChanged
  nameWithType: SpeechRecognitionEngine.AudioStateChanged
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged
- uid: System.EventHandler{System.Speech.Recognition.AudioStateChangedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioStateChangedEventArgs>
  nameWithType: EventHandler<AudioStateChangedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioStateChangedEventArgs
    name: AudioStateChangedEventArgs
    nameWithType: AudioStateChangedEventArgs
    fullName: AudioStateChangedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: BabbleTimeout
  nameWithType: SpeechRecognitionEngine.BabbleTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Dispose
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Dispose()
  nameWithType: SpeechRecognitionEngine.Dispose()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Dispose()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Dispose(System.Boolean)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Dispose(Boolean)
  nameWithType: SpeechRecognitionEngine.Dispose(Boolean)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Dispose(Boolean)
- uid: System.Boolean
  parent: System
  isExternal: true
  name: Boolean
  nameWithType: Boolean
  fullName: System.Boolean
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognize(String)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(String)
- uid: System.Speech.Recognition.RecognitionResult
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognitionResult
  nameWithType: RecognitionResult
  fullName: System.Speech.Recognition.RecognitionResult
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
- uid: System.Speech.Recognition.RecognizedWordUnit[]
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizedWordUnit
  nameWithType: RecognizedWordUnit
  fullName: System.Speech.Recognition.RecognizedWordUnit[]
  spec.csharp:
  - uid: System.Speech.Recognition.RecognizedWordUnit
    name: RecognizedWordUnit
    nameWithType: RecognizedWordUnit
    fullName: RecognizedWordUnit[]
  - name: '[]'
    nameWithType: '[]'
    fullName: '[]'
- uid: System.Globalization.CompareOptions
  parent: System.Globalization
  isExternal: true
  name: CompareOptions
  nameWithType: CompareOptions
  fullName: System.Globalization.CompareOptions
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognize(String,CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(String,CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognizeAsync(String)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(String)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognizeAsync(String,CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(String,CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognizeCompleted
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted
- uid: System.EventHandler{System.Speech.Recognition.EmulateRecognizeCompletedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<EmulateRecognizeCompletedEventArgs>
  nameWithType: EventHandler<EmulateRecognizeCompletedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.EmulateRecognizeCompletedEventArgs
    name: EmulateRecognizeCompletedEventArgs
    nameWithType: EmulateRecognizeCompletedEventArgs
    fullName: EmulateRecognizeCompletedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EndSilenceTimeout
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EndSilenceTimeoutAmbiguous
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Grammars
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Grammars
  nameWithType: SpeechRecognitionEngine.Grammars
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Grammars
- uid: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.Grammar}
  parent: System.Collections.ObjectModel
  isExternal: true
  name: ReadOnlyCollection<Grammar>
  nameWithType: ReadOnlyCollection<Grammar>
  fullName: System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.Grammar>
  spec.csharp:
  - uid: System.Collections.ObjectModel.ReadOnlyCollection`1
    name: ReadOnlyCollection
    nameWithType: ReadOnlyCollection
    fullName: ReadOnlyCollection<System.Speech.Recognition.Grammar>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.Grammar
    name: Grammar
    nameWithType: Grammar
    fullName: Grammar
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: InitialSilenceTimeout
  nameWithType: SpeechRecognitionEngine.InitialSilenceTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: InstalledRecognizers()
  nameWithType: SpeechRecognitionEngine.InstalledRecognizers()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers()
- uid: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.RecognizerInfo}
  parent: System.Collections.ObjectModel
  isExternal: true
  name: ReadOnlyCollection<RecognizerInfo>
  nameWithType: ReadOnlyCollection<RecognizerInfo>
  fullName: System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.RecognizerInfo>
  spec.csharp:
  - uid: System.Collections.ObjectModel.ReadOnlyCollection`1
    name: ReadOnlyCollection
    nameWithType: ReadOnlyCollection
    fullName: ReadOnlyCollection<System.Speech.Recognition.RecognizerInfo>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.RecognizerInfo
    name: RecognizerInfo
    nameWithType: RecognizerInfo
    fullName: RecognizerInfo
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: LoadGrammar(Grammar)
  nameWithType: SpeechRecognitionEngine.LoadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(Grammar)
- uid: System.Speech.Recognition.Grammar
  parent: System.Speech.Recognition
  isExternal: false
  name: Grammar
  nameWithType: Grammar
  fullName: System.Speech.Recognition.Grammar
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: LoadGrammarAsync(Grammar)
  nameWithType: SpeechRecognitionEngine.LoadGrammarAsync(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(Grammar)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: LoadGrammarCompleted
  nameWithType: SpeechRecognitionEngine.LoadGrammarCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted
- uid: System.EventHandler{System.Speech.Recognition.LoadGrammarCompletedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<LoadGrammarCompletedEventArgs>
  nameWithType: EventHandler<LoadGrammarCompletedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.LoadGrammarCompletedEventArgs
    name: LoadGrammarCompletedEventArgs
    nameWithType: LoadGrammarCompletedEventArgs
    fullName: LoadGrammarCompletedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: MaxAlternates
  nameWithType: SpeechRecognitionEngine.MaxAlternates
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates
- uid: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: QueryRecognizerSetting(String)
  nameWithType: SpeechRecognitionEngine.QueryRecognizerSetting(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(String)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Recognize
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Recognize()
  nameWithType: SpeechRecognitionEngine.Recognize()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Recognize()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Recognize(TimeSpan)
  nameWithType: SpeechRecognitionEngine.Recognize(TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Recognize(TimeSpan)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsync()
  nameWithType: SpeechRecognitionEngine.RecognizeAsync()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsync(RecognizeMode)
  nameWithType: SpeechRecognitionEngine.RecognizeAsync(RecognizeMode)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(RecognizeMode)
- uid: System.Speech.Recognition.RecognizeMode
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizeMode
  nameWithType: RecognizeMode
  fullName: System.Speech.Recognition.RecognizeMode
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsyncCancel()
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncCancel()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsyncStop()
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncStop()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeCompleted
  nameWithType: SpeechRecognitionEngine.RecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted
- uid: System.EventHandler{System.Speech.Recognition.RecognizeCompletedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<RecognizeCompletedEventArgs>
  nameWithType: EventHandler<RecognizeCompletedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.RecognizeCompletedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.RecognizeCompletedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.RecognizeCompletedEventArgs
    name: RecognizeCompletedEventArgs
    nameWithType: RecognizeCompletedEventArgs
    fullName: RecognizeCompletedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognitionEngine.RecognizerAudioPosition
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizerInfo
  nameWithType: SpeechRecognitionEngine.RecognizerInfo
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizerUpdateReached
  nameWithType: SpeechRecognitionEngine.RecognizerUpdateReached
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached
- uid: System.EventHandler{System.Speech.Recognition.RecognizerUpdateReachedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<RecognizerUpdateReachedEventArgs>
  nameWithType: EventHandler<RecognizerUpdateReachedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.RecognizerUpdateReachedEventArgs
    name: RecognizerUpdateReachedEventArgs
    nameWithType: RecognizerUpdateReachedEventArgs
    fullName: RecognizerUpdateReachedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RequestRecognizerUpdate()
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RequestRecognizerUpdate(Object)
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate(Object)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(Object)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RequestRecognizerUpdate(Object,TimeSpan)
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate(Object,TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(Object,TimeSpan)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
  nameWithType: SpeechRecognitionEngine.SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
- uid: System.IO.Stream
  parent: System.IO
  isExternal: true
  name: Stream
  nameWithType: Stream
  fullName: System.IO.Stream
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToDefaultAudioDevice()
  nameWithType: SpeechRecognitionEngine.SetInputToDefaultAudioDevice()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToNull()
  nameWithType: SpeechRecognitionEngine.SetInputToNull()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToWaveFile(String)
  nameWithType: SpeechRecognitionEngine.SetInputToWaveFile(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(String)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToWaveStream(Stream)
  nameWithType: SpeechRecognitionEngine.SetInputToWaveStream(Stream)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(Stream)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechDetected
  nameWithType: SpeechRecognitionEngine.SpeechDetected
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected
- uid: System.EventHandler{System.Speech.Recognition.SpeechDetectedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechDetectedEventArgs>
  nameWithType: EventHandler<SpeechDetectedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechDetectedEventArgs
    name: SpeechDetectedEventArgs
    nameWithType: SpeechDetectedEventArgs
    fullName: SpeechDetectedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechHypothesized
  nameWithType: SpeechRecognitionEngine.SpeechHypothesized
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized
- uid: System.EventHandler{System.Speech.Recognition.SpeechHypothesizedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechHypothesizedEventArgs>
  nameWithType: EventHandler<SpeechHypothesizedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechHypothesizedEventArgs
    name: SpeechHypothesizedEventArgs
    nameWithType: SpeechHypothesizedEventArgs
    fullName: SpeechHypothesizedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionRejected
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionRejected
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected
- uid: System.EventHandler{System.Speech.Recognition.SpeechRecognitionRejectedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechRecognitionRejectedEventArgs>
  nameWithType: EventHandler<SpeechRecognitionRejectedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechRecognitionRejectedEventArgs
    name: SpeechRecognitionRejectedEventArgs
    nameWithType: SpeechRecognitionRejectedEventArgs
    fullName: SpeechRecognitionRejectedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognized
  nameWithType: SpeechRecognitionEngine.SpeechRecognized
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized
- uid: System.EventHandler{System.Speech.Recognition.SpeechRecognizedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechRecognizedEventArgs>
  nameWithType: EventHandler<SpeechRecognizedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechRecognizedEventArgs
    name: SpeechRecognizedEventArgs
    nameWithType: SpeechRecognizedEventArgs
    fullName: SpeechRecognizedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UnloadAllGrammars()
  nameWithType: SpeechRecognitionEngine.UnloadAllGrammars()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UnloadGrammar(Grammar)
  nameWithType: SpeechRecognitionEngine.UnloadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(Grammar)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UpdateRecognizerSetting(String,Int32)
  nameWithType: SpeechRecognitionEngine.UpdateRecognizerSetting(String,Int32)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(String,Int32)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UpdateRecognizerSetting(String,String)
  nameWithType: SpeechRecognitionEngine.UpdateRecognizerSetting(String,String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(String,String)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionEngine
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioFormat
  nameWithType: SpeechRecognitionEngine.AudioFormat
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioLevel
  nameWithType: SpeechRecognitionEngine.AudioLevel
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioPosition
  nameWithType: SpeechRecognitionEngine.AudioPosition
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioState*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioState
  nameWithType: SpeechRecognitionEngine.AudioState
- uid: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: BabbleTimeout
  nameWithType: SpeechRecognitionEngine.BabbleTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Dispose*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Dispose
  nameWithType: SpeechRecognitionEngine.Dispose
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognize
  nameWithType: SpeechRecognitionEngine.EmulateRecognize
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognizeAsync
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EndSilenceTimeout
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EndSilenceTimeoutAmbiguous
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Grammars*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Grammars
  nameWithType: SpeechRecognitionEngine.Grammars
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: InitialSilenceTimeout
  nameWithType: SpeechRecognitionEngine.InitialSilenceTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: InstalledRecognizers
  nameWithType: SpeechRecognitionEngine.InstalledRecognizers
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: LoadGrammar
  nameWithType: SpeechRecognitionEngine.LoadGrammar
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: LoadGrammarAsync
  nameWithType: SpeechRecognitionEngine.LoadGrammarAsync
- uid: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: MaxAlternates
  nameWithType: SpeechRecognitionEngine.MaxAlternates
- uid: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: QueryRecognizerSetting
  nameWithType: SpeechRecognitionEngine.QueryRecognizerSetting
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Recognize*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Recognize
  nameWithType: SpeechRecognitionEngine.Recognize
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsync
  nameWithType: SpeechRecognitionEngine.RecognizeAsync
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsyncCancel
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncCancel
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsyncStop
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncStop
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognitionEngine.RecognizerAudioPosition
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizerInfo
  nameWithType: SpeechRecognitionEngine.RecognizerInfo
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RequestRecognizerUpdate
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToAudioStream
  nameWithType: SpeechRecognitionEngine.SetInputToAudioStream
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToDefaultAudioDevice
  nameWithType: SpeechRecognitionEngine.SetInputToDefaultAudioDevice
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToNull
  nameWithType: SpeechRecognitionEngine.SetInputToNull
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToWaveFile
  nameWithType: SpeechRecognitionEngine.SetInputToWaveFile
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToWaveStream
  nameWithType: SpeechRecognitionEngine.SetInputToWaveStream
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UnloadAllGrammars
  nameWithType: SpeechRecognitionEngine.UnloadAllGrammars
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UnloadGrammar
  nameWithType: SpeechRecognitionEngine.UnloadGrammar
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UpdateRecognizerSetting
  nameWithType: SpeechRecognitionEngine.UpdateRecognizerSetting
